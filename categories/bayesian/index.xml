<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian on Dr. Juan Camilo Orduz</title>
    <link>/categories/bayesian/</link>
    <description>Recent content in Bayesian on Dr. Juan Camilo Orduz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 24 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/bayesian/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Scikit-Learn Example in PyMC: Gaussian Process Classifier</title>
      <link>/sklearn_pymc_classifier/</link>
      <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/sklearn_pymc_classifier/</guid>
      <description>In this notebook we want to describe how to port a couple of classification examples from scikit-learn‚Äôs documentation (classifier comparison) to PyMC. We focus in the classical moons synthetic dataset.
Prepare Notebook import arviz as az import matplotlib.pyplot as plt import numpy as np import pandas as pd import pymc as pm import pymc.sampling_jax import seaborn as sns from sklearn.datasets import make_moons from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_split plt.</description>
    </item>
    
    <item>
      <title>Synthetic Control in PyMC</title>
      <link>/synthetic_control_pymc/</link>
      <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/synthetic_control_pymc/</guid>
      <description>Synthetic control can be considered ‚Äúthe most important innovation in the policy evaluation literature in the last few years‚Äù (see The State of Applied Econometrics: Causality and Policy Evaluation by Susan Athey and Guido W. Imbens).
 In this notebook we provide an example of how to implement a synthetic control problem in PyMC to answer a ‚Äúwhat if this had happened?‚Äù type of question in the context of causal inference.</description>
    </item>
    
    <item>
      <title>Modeling Short Time Series with Prior Knowledge in PyMC</title>
      <link>/short_time_series_pymc/</link>
      <pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>/short_time_series_pymc/</guid>
      <description>In this notebook I want to reproduce in PyMC the methodology described in the amazing blog post Modeling Short Time Series with Prior Knowledge by Tim Radtke to forecast short time series using bayesian transfer learning üöÄ. The main idea is to transfer information (e.g.¬†long term seasonality) from a long time series to a short time series via prior distributions. Tim‚Äôs blog post treats a very concrete example where all the concepts become very concrete.</description>
    </item>
    
    <item>
      <title>Time-Varying Regression Coefficients via Gaussian Random Walk in PyMC</title>
      <link>/bikes_pymc/</link>
      <pubDate>Sun, 03 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>/bikes_pymc/</guid>
      <description>In this notebook we want to illustrate how to use PyMC to fit a time-varying coefficient regression model. The motivation comes from post Exploring Tools for Interpretable Machine Learning where we studied a time series problem, regarding the prediction of the number of bike rentals, from a machine learning perspective. Concretely, we fitted and compared two machine learning models: a linear regression with interactions and a gradient boost model (XGBoost).</description>
    </item>
    
    <item>
      <title>PyConDE &amp; PyData Berlin 2022: Introduction to Uplift Modeling</title>
      <link>/uplift/</link>
      <pubDate>Mon, 11 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/uplift/</guid>
      <description>In this notebook we present a simple example of uplift modeling estimation via meta-models using causalml and scikit-uplift. For a more detailed introduction to uplift modeling, see:
 Diemert, Eustache, et.al. (2020) ‚ÄúA Large Scale Benchmark for Uplift Modeling‚Äù
 Gutierrez, P., &amp;amp; G√©rardy, J. Y. (2017). ‚ÄúCausal Inference and Uplift Modelling: A Review of the Literature‚Äù
 Karlsson, H. (2019) ‚ÄúUplift Modeling: Identifying Optimal Treatment Group Allocation and Whom to Contact to Maximize Return on Investment‚Äù</description>
    </item>
    
    <item>
      <title>Gamma-Gamma Model of Monetary Value in PyMC</title>
      <link>/gamma_gamma_pymc/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/gamma_gamma_pymc/</guid>
      <description>In this notebook we describe how to fit Fader‚Äôs and Hardie‚Äôs gamma-gamma model presented in the paper ‚ÄúRFM and CLV: Using Iso-value Curves for Customer Base Analysis‚Äù and the note ‚ÄúThe Gamma-Gamma Model of Monetary Value‚Äù. The approach is very similar as the one presented in the previous post BG/NBD Model in PyMC where we simply ported the log-likelihood of the lifetimes package from numpy to theano.
Prepare Notebook import arviz as az import matplotlib.</description>
    </item>
    
    <item>
      <title>BG/NBD Model in PyMC</title>
      <link>/bg_nbd_pymc/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>/bg_nbd_pymc/</guid>
      <description>In this notebook we show how to port the BG/NBD model from the the lifetimes (developed mainly by Cameron Davidson-Pilon) package to pymc. The BG/NBD model, introduced in the seminal paper ‚ÄúCounting Your Customers‚Äù the Easy Way: An Alternative to the Pareto/NBD Model by Peter S. Fader, Bruce G. S. Hardie and Ka Lok Lee in 2005, is used to
 predict future purchasing patterns, which can then serve as an input into ‚Äúlifetime value‚Äù calculations, in the ‚Äúnon-contractual‚Äù setting (i.</description>
    </item>
    
    <item>
      <title>Media Effect Estimation with PyMC: Adstock, Saturation &amp; Diminishing Returns</title>
      <link>/pymc_mmm/</link>
      <pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/pymc_mmm/</guid>
      <description>In this notebook we present a concrete example of estimating the media effects via bayesian methods, following the strategy outlined in Google‚Äôs paper Jin, Yuxue, et al.¬†‚ÄúBayesian methods for media mix modeling with carryover and shape effects.‚Äù (2017). This example can be considered the continuation of the post Media Effect Estimation with Orbit‚Äôs KTR Model. However, it is not strictly necessary to read before as we make this notebook self-contained.</description>
    </item>
    
    <item>
      <title>Media Effect Estimation with Orbit&#39;s KTR Model</title>
      <link>/orbit_mmm/</link>
      <pubDate>Fri, 04 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/orbit_mmm/</guid>
      <description>In this notebook we want to experiment to the new KTR model included in the new orbit‚Äôs release (1.1). In particular, we are interested in its applications to media effects estimation in the context of media mix modeling. This is one of the applications for the KTR model by the Uber‚Äôs team, see the corresponding paper Edwin, Ng, et al.¬†‚ÄúBayesian Time Varying Coefficient Model with Applications to Marketing Mix Modeling‚Äù.</description>
    </item>
    
    <item>
      <title>Unobserved Components Model as a Bayesian Model with PyMC</title>
      <link>/uc_pymc/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/uc_pymc/</guid>
      <description>In this notebook I want to deep-dive into the idea of wrapping a statsmodels UnobservedComponents model as a bayesian model with PyMC described in the (great!) post Fast Bayesian estimation of SARIMAX models. This is a nice excuse to get into some internals of how PyMC works. I hope this can serve as a complement to the original post mentioned above. This post has two parts: In the first one we fit a UnobservedComponents model to a simulated time series.</description>
    </item>
    
    <item>
      <title>Simple Bayesian Linear Regression with TensorFlow Probability</title>
      <link>/tfp_lm/</link>
      <pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/tfp_lm/</guid>
      <description>In this post we show how to fit a simple linear regression model using TensorFlow Probability by replicating the first example on the getting started guide for PyMC3. We are going to use Auto-Batched Joint Distributions as they simplify the model specification considerably. Moreover, there is a great resource to get deeper into this type of distribution: Auto-Batched Joint Distributions: A Gentle Tutorial, which I strongly recommend (see this post to get a brief introduction on TensorFlow probability distributions).</description>
    </item>
    
    <item>
      <title>A Simple Hamiltonian Monte Carlo Example with TensorFlow Probability</title>
      <link>/tfp_hcm/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/tfp_hcm/</guid>
      <description>In this post we want to revisit a simple bayesian inference example worked out in this blog post. This time we want to use TensorFlow Probability (TFP) instead of PyMC3.
References:
 Statistical Rethinking is an amazing reference for Bayesian analysis. It also has a sequence of online lectures freely available on YouTube.
 An introduction to probabilistic programming, now available in TensorFlow Probability
 There are many examples on the TensorFlow‚Äôs GitHub repository.</description>
    </item>
    
    <item>
      <title>Introduction to Bayesian Modeling with PyMC3</title>
      <link>/intro_pymc3/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/intro_pymc3/</guid>
      <description>We give an introduction to PyMC3, a probabilistic programming framework written in Python. We revise the basic mahematical theory and present two concrete examples.</description>
    </item>
    
  </channel>
</rss>
