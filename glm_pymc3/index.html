<!DOCTYPE html>
<html lang="en-us">
  <head>
    <script defer src="https://use.fontawesome.com/releases/v6.5.1/js/all.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-5NM5EDH834"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5NM5EDH834');
</script>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.1" />


<title>GLM in PyMC3: Out-Of-Sample Predictions - Dr. Juan Camilo Orduz</title>
<meta property="og:title" content="GLM in PyMC3: Out-Of-Sample Predictions - Dr. Juan Camilo Orduz">


  <link href='../images/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/tattoo_logo.jpg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../about/"> About</a></li>
    
    <li><a href="https://github.com/juanitorduz"><i class='fab fa-github fa-2x'></i>  </a></li>
    
    <li><a href="https://www.linkedin.com/in/juanitorduz/"><i class='fab fa-linkedin fa-2x' style='color:#0a66c2;'></i>  </a></li>
    
    <li><a href="https://ko-fi.com/juanitorduz"><i class='fa-solid fa-mug-hot fa-2x' style='color:#FF5E5B;'></i>  </a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">8 min read</span>
    

    <h1 class="article-title">GLM in PyMC3: Out-Of-Sample Predictions</h1>

    
    <span class="article-date">2021-01-04</span>
    

    <div class="article-content">
      


<p>In this notebook I explore the <a href="https://docs.pymc.io/api/glm.html">glm</a> module of <a href="https://docs.pymc.io/">PyMC3</a>. I am particularly interested in the model definition using <a href="https://patsy.readthedocs.io/en/latest/">patsy</a> formulas, as it makes the model evaluation loop faster (easier to include features and/or interactions). There are many good resources on this subject, but most of them evaluate the model in-sample. For many applications we require doing predictions on out-of-sample data. This experiment was motivated by the discussion of the thread <a href="https://discourse.pymc.io/t/out-of-sample-predictions-with-the-glm-sub-module/773">‚ÄúOut of sample‚Äù predictions with the GLM sub-module</a> on the (great!) forum <a href="https://discourse.pymc.io/">discourse.pymc.io/</a>, thank you all for your input!</p>
<p style="color:red">
üì¢ <strong>WARNING:</strong>
</p>
<p>Since <code>pymc v4</code> the <code>GLM</code> module has been depreciated in favor of <a href="https://bambinos.github.io/bambi/">Bambi</a>, a more complete implementation of the GLM sub-module which also allows for mixed-effects models. If you are coming from <code>pymc</code> you can take a look into a tutorial I wrote (together with <a href="https://github.com/tomicapretto">Tom√°s Capretto</a>) about how to port a hierarchical bayesian model from <code>pymc</code> to <code>bambi</code> <a href="https://bambinos.github.io/bambi/main/notebooks/radon_example.html">here</a>. That being said, <strong>besides the syntax in the model specification, the rest of the concepts and code of this post remain valid!</strong> üòâ. Moreover, you can find an updated version of this notebook (thanks <a href="https://github.com/drbenvincent">Benjamin T. Vincent</a>!) <a href="https://www.pymc.io/projects/examples/en/latest/generalized_linear_models/GLM-out-of-sample-predictions.html">here</a>, as part of the PyMC example gallery.</p>
<hr />
<p><strong>Resources</strong></p>
<ul>
<li><p><a href="https://docs.pymc.io/nb_examples/index.html">PyMC3 Docs: Example Notebooks</a></p>
<ul>
<li>In particular check <a href="https://docs.pymc.io/notebooks/GLM-logistic.html">GLM: Logistic Regression</a></li>
</ul></li>
<li><p><a href="https://github.com/aloctavodia/BAP/blob/master/code/Chp4/04_Generalizing_linear_models.ipynb">Bayesian Analysis with Python (Second edition) - Chapter 4</a></p></li>
<li><p><a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a></p></li>
</ul>
<p><strong>Acknowledgement:</strong> I would like to thank the <a href="https://github.com/pymc-devs">pymc-devs</a> team for their support and valuable input refining the initial version of this post.</p>
<div id="prepare-notebook" class="section level2">
<h2>Prepare Notebook</h2>
<pre class="python"><code>import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

sns.set_style(
    style=&quot;darkgrid&quot;, 
    rc={&quot;axes.facecolor&quot;: &quot;.9&quot;, &quot;grid.color&quot;: &quot;.8&quot;}
)
sns.set_palette(palette=&quot;deep&quot;)
sns_c = sns.color_palette(palette=&quot;deep&quot;)

import arviz as az
import patsy
import pymc3 as pm
from pymc3 import glm

plt.rcParams[&quot;figure.figsize&quot;] = [7, 6]
plt.rcParams[&quot;figure.dpi&quot;] = 100</code></pre>
</div>
<div id="generate-sample-data" class="section level2">
<h2>Generate Sample Data</h2>
<p>We want to fit a logistic regression model where there is a multiplicative interaction between two numerical features.</p>
<pre class="python"><code>SEED = 42
np.random.seed(SEED)

# Number of data points.
n = 250
# Create features.
x1 = np.random.normal(loc=0.0, scale=2.0, size=n)
x2 = np.random.normal(loc=0.0, scale=2.0, size=n)
epsilon = np.random.normal(loc=0.0, scale=0.5, size=n)
# Define target variable.
intercept = -0.5
beta_x1 = 1
beta_x2 = -1
beta_interaction = 2
z = intercept + beta_x1 * x1 + beta_x2 * x2 + beta_interaction * x1 * x2
p = 1 / (1 + np.exp(-z))
y = np.random.binomial(n=1, p=p, size=n)

df = pd.DataFrame(dict(x1=x1, x2=x2, y=y))

df.head()</code></pre>
<center>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
x1
</th>
<th>
x2
</th>
<th>
y
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.993428
</td>
<td>
-2.521768
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
-0.276529
</td>
<td>
1.835724
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1.295377
</td>
<td>
4.244312
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3.046060
</td>
<td>
2.064931
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
-0.468307
</td>
<td>
-3.038740
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
</center>
<p>Let us do some exploration of the data:</p>
<pre class="python"><code>sns.pairplot(
    data=df,
    kind=&quot;scatter&quot;,
    height=2,
    plot_kws={&quot;color&quot;: sns_c[1]},
    diag_kws={&quot;color&quot;: sns_c[2]}
);</code></pre>
<center>
<div class="figure">
<img src="../images/glm_pymc3_files/glm_pymc3_6_0.svg" alt="" />
<p class="caption">svg</p>
</div>
</center>
<ul>
<li><span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are not correlated.</li>
<li><span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> do not seem to separate the <span class="math inline">\(y\)</span>-classes independently.</li>
<li>The distribution of <span class="math inline">\(y\)</span> is not highly unbalanced.</li>
</ul>
<pre class="python"><code>fig, ax = plt.subplots()
sns_c_div = sns.diverging_palette(240, 10, n=2)
sns.scatterplot(
  x=&quot;x1&quot;,
  y=&quot;x2&quot;,
  data=df,
  hue=&quot;y&quot;,
  palette=[sns_c_div[0], sns_c_div[-1]]
)
ax.legend(title=&quot;y&quot;, loc=&quot;center left&quot;, bbox_to_anchor=(1, 0.5))
ax.set(
  title=&quot;Sample Data&quot;,
  xlim=(-9, 9),
  ylim=(-9, 9),
  xlabel=&quot;x1&quot;,
  ylabel=&quot;x2&quot;
);</code></pre>
<center>
<div class="figure">
<img src="../images/glm_pymc3_files/glm_pymc3_8_0.svg" alt="" />
<p class="caption">svg</p>
</div>
</center>
</div>
<div id="prepare-data-for-modeling" class="section level2">
<h2>Prepare Data for Modeling</h2>
<p>I wanted to use the <em><code>classmethod</code></em> <code>from_formula</code> (see <a href="https://docs.pymc.io/api/glm.html">documentation</a>), but I was not able to generate out-of-sample predictions with this approach (if you find a way please let me know!). As a workaround, I created the features from a formula using <a href="https://patsy.readthedocs.io/en/latest/">patsy</a> directly and then use <em><code>class</code></em> <code>pymc3.glm.linear.GLM</code> (this was motivated by going into the <a href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/glm/linear.py">source code</a>).</p>
<pre class="python"><code># Define model formula.
formula = &quot;y ~ x1 * x2&quot;
# Create features.
y, x = patsy.dmatrices(formula_like=formula, data=df)
y = np.asarray(y).flatten()
labels = x.design_info.column_names
x = np.asarray(x)</code></pre>
<p>As pointed out on the <a href="https://discourse.pymc.io/t/out-of-sample-predictions-with-the-glm-sub-module/773">thread</a> (thank you <span class="citation">@Nicky</span>!), we need to keep the lables of the features in the design matrix.</p>
<pre class="python"><code>print(f&quot;labels = {labels}&quot;)</code></pre>
<pre><code>labels = [&#39;Intercept&#39;, &#39;x1&#39;, &#39;x2&#39;, &#39;x1:x2&#39;]</code></pre>
<p>Now we do a train-test split.</p>
<pre class="python"><code>from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(
  x, y, train_size=0.7, random_state=SEED
)</code></pre>
</div>
<div id="define-the-model" class="section level2">
<h2>Define the Model</h2>
<p>We now specify the model in PyMC3.</p>
<pre class="python"><code>with pm.Model() as model:
    # Set data container.
    data = pm.Data(&quot;data&quot;, x_train)
    # Define GLM family.
    family = pm.glm.families.Binomial()
    # Set priors.
    priors = {
        &quot;Intercept&quot;: pm.Normal.dist(mu=0, sd=10),
        &quot;x1&quot;: pm.Normal.dist(mu=0, sd=10),
        &quot;x2&quot;: pm.Normal.dist(mu=0, sd=10),
        &quot;x1:x2&quot;: pm.Normal.dist(mu=0, sd=10),
    }
    # Specify model.
    glm.GLM(
      y=y_train,
      x=data,
      family=family,
      intercept=False,
      labels=labels,
      priors=priors
    )</code></pre>
</div>
<div id="prior-checks" class="section level2">
<h2>Prior Checks</h2>
<p>Before fitting the model we run some prior predictive checks on the training data.</p>
<pre class="python"><code># Sample from prior distribution.
with model:
    prior_checks = pm.sample_prior_predictive(samples=100, random_seed=SEED)</code></pre>
<p>We get samples for all our variables and the output:</p>
<pre class="python"><code>prior_checks.keys()</code></pre>
<pre><code>dict_keys([&#39;y&#39;, &#39;Intercept&#39;, &#39;x2&#39;, &#39;x1:x2&#39;, &#39;x1&#39;])</code></pre>
<p>Let us take a look into the samples. For the target variable <code>y</code> we have:</p>
<pre class="python"><code>prior_checks[&quot;y&quot;]</code></pre>
<pre><code>array([[0, 1, 0, ..., 1, 0, 0],
       [0, 1, 0, ..., 1, 0, 0],
       [1, 1, 0, ..., 0, 0, 0],
       ...,
       [1, 0, 0, ..., 0, 1, 0],
       [0, 1, 0, ..., 0, 0, 0],
       [1, 1, 0, ..., 0, 0, 0]])</code></pre>
<p>So we can get summarize the model predictions (before seeing the data) by taking the mean over the samples. Let us store this in a dataframe to in order to generate some plots.</p>
<pre class="python"><code>train_prior_df = pd.DataFrame(
    data={
        &quot;x1_train&quot;: x_train[:, 1],
        &quot;x2_train&quot;: x_train[:, 2],
        &quot;y_train&quot;: y_train,
        &quot;y_train_prior_mean&quot;: prior_checks[&quot;y&quot;].mean(axis=0),
    },
)

train_prior_df.sort_values(&quot;y_train&quot;, inplace=True)</code></pre>
<p>First we plot the distribution of the means:</p>
<pre class="python"><code># Plot means distribution.
fig, ax = plt.subplots()
sns.kdeplot(
    x=&quot;y_train_prior_mean&quot;,
    data=train_prior_df,
    hue=&quot;y_train&quot;,
    palette=[sns_c[0], sns_c[3]],
    fill=True,
    alpha=0.1,
    ax=ax,
)
ax.axvline(x=0.5, color=&quot;gray&quot;, linestyle=&quot;--&quot;)
ax.set(title=&quot;Prior Means Distribution (train)&quot;, xlim=(0, 1));</code></pre>
<center>
<div class="figure">
<img src="../images/glm_pymc3_files/glm_pymc3_26_0.svg" alt="" />
<p class="caption">svg</p>
</div>
</center>
<p>We clearly see that the model can not distinguish between the two classes yet. This makes sense as we have non-informative priors for this synthetic data set. We can also confirm this if we plot each point separately:</p>
<pre class="python"><code>fig, ax = plt.subplots()
cmap = sns.diverging_palette(240, 10, n=50, as_cmap=True)
sns.scatterplot(
    x=&quot;x1_train&quot;,
    y=&quot;x2_train&quot;,
    data=train_prior_df,
    hue=&quot;y_train_prior_mean&quot;,
    hue_norm=(0, 1),
    palette=cmap,
    edgecolor=&quot;black&quot;,
    style=&quot;y_train&quot;,
    ax=ax,
)
ax.legend(loc=&quot;center left&quot;, bbox_to_anchor=(1, 0.5))
ax.set(
  title=&quot;Prior Means (train)&quot;,
  xlim=(-9, 9),
  ylim=(-9, 9),
  xlabel=&quot;x1&quot;,
  ylabel=&quot;x2&quot;
);</code></pre>
<center>
<div class="figure">
<img src="../images/glm_pymc3_files/glm_pymc3_28_0.svg" alt="" />
<p class="caption">svg</p>
</div>
</center>
</div>
<div id="fit-model" class="section level2">
<h2>Fit Model</h2>
<pre class="python"><code>with model:
    # Configure sampler.
    trace = pm.sample(5000, chains=5, tune=1000, target_accept=0.87, random_seed=SEED)</code></pre>
<pre class="python"><code># Plot chains.
az.plot_trace(data=trace);</code></pre>
<center>
<img src="../images/glm_pymc3_files/glm_pymc3_31_0.svg" alt="samples" style="width: 1000px;"/>
</center>
<pre class="python"><code>az.summary(trace)</code></pre>
<center>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
mean
</th>
<th>
sd
</th>
<th>
hdi_3%
</th>
<th>
hdi_97%
</th>
<th>
mcse_mean
</th>
<th>
mcse_sd
</th>
<th>
ess_bulk
</th>
<th>
ess_tail
</th>
<th>
r_hat
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Intercept
</th>
<td>
-0.536
</td>
<td>
0.262
</td>
<td>
-1.043
</td>
<td>
-0.060
</td>
<td>
0.002
</td>
<td>
0.002
</td>
<td>
14479.0
</td>
<td>
16189.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
x1
</th>
<td>
0.616
</td>
<td>
0.211
</td>
<td>
0.223
</td>
<td>
1.013
</td>
<td>
0.002
</td>
<td>
0.001
</td>
<td>
14573.0
</td>
<td>
14635.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
x2
</th>
<td>
-0.865
</td>
<td>
0.221
</td>
<td>
-1.285
</td>
<td>
-0.466
</td>
<td>
0.002
</td>
<td>
0.001
</td>
<td>
12761.0
</td>
<td>
14415.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
x1:x2
</th>
<td>
1.790
</td>
<td>
0.335
</td>
<td>
1.162
</td>
<td>
2.403
</td>
<td>
0.003
</td>
<td>
0.002
</td>
<td>
12686.0
</td>
<td>
14676.0
</td>
<td>
1.0
</td>
</tr>
</tbody>
</table>
</div>
</center>
<p>The chains look good.</p>
</div>
<div id="generate-out-of-sample-predictions" class="section level2">
<h2>Generate Out-Of-Sample Predictions</h2>
<p>Now we generate predictions on the test set.</p>
<pre class="python"><code># Update data reference.
pm.set_data({&quot;data&quot;: x_test}, model=model)
# Generate posterior samples.
ppc_test = pm.sample_posterior_predictive(trace, model=model, samples=1000)</code></pre>
<pre class="python"><code># Compute the point prediction by taking the mean
# and defining the category via a threshold.
p_test_pred = ppc_test[&quot;y&quot;].mean(axis=0)
y_test_pred = (p_test_pred &gt;= 0.5).astype(&quot;int&quot;)</code></pre>
</div>
<div id="evaluate-model" class="section level2">
<h2>Evaluate Model</h2>
<p>First let us compute the accuracy on the test set.</p>
<pre class="python"><code>from sklearn.metrics import accuracy_score

print(f&quot;accuracy = {accuracy_score(y_true=y_test, y_pred=y_test_pred): 0.3f}&quot;)</code></pre>
<pre><code>accuracy =  0.787</code></pre>
<p>Next, we plot the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">roc curve</a> and compute the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve">auc</a>.</p>
<pre class="python"><code>from sklearn.metrics import RocCurveDisplay, auc, roc_curve

fpr, tpr, thresholds = roc_curve(
    y_true=y_test, y_score=p_test_pred, pos_label=1, drop_intermediate=False
)
roc_auc = auc(fpr, tpr)

fig, ax = plt.subplots()
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)
roc_display = roc_display.plot(ax=ax, marker=&quot;o&quot;, color=sns_c[4], markersize=4)
ax.set(title=&quot;ROC&quot;);</code></pre>
<center>
<div class="figure">
<img src="../images/glm_pymc3_files/glm_pymc3_40_0.svg" alt="" />
<p class="caption">svg</p>
</div>
</center>
<p>The model is performing as expected (we of course know the data generating process, which is almost never the case in practical applications).</p>
</div>
<div id="model-decision-boundary" class="section level2">
<h2>Model Decision Boundary</h2>
<p>Finally we will describe and plot the model decision boundary, which is the space defined as</p>
<p><span class="math display">\[\mathcal{B} = \{(x_1, x_2) \in \mathbb{R}^2 \: | \: p(x_1, x_2) = 0.5\}\]</span></p>
<p>where <span class="math inline">\(p\)</span> denotes the probability of belonging to the class <span class="math inline">\(y=1\)</span> output by the model. To make this set explicit, we simply write the condition in terms of the model parametrization:</p>
<p><span class="math display">\[0.5 = \frac{1}{1 + \exp(-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{12} x_1x_2))}\]</span></p>
<p>which implies</p>
<p><span class="math display">\[0 = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{12} x_1x_2\]</span></p>
<p>Solving for <span class="math inline">\(x_2\)</span> we get the formula</p>
<p><span class="math display">\[x_2 = - \frac{\beta_0 + \beta_1 x_1}{\beta_2 + \beta_{12}x_1}\]</span></p>
<p>Observe that this curve is a hyperbola centered at the singularity point <span class="math inline">\(x_1 = - \beta_2 / \beta_{12}\)</span>.</p>
<p>Let us now plot the model decision boundary using a grid:</p>
<pre class="python"><code># Construct grid.
x1_grid = np.linspace(start=-9, stop=9, num=300)
x2_grid = x1_grid

x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)

x_grid = np.stack(arrays=[x1_mesh.flatten(), x2_mesh.flatten()], axis=1)

# Create features on the grid.
x_grid_ext = patsy.dmatrix(
  formula_like=&quot;x1 * x2&quot;, data=dict(x1=x_grid[:, 0], x2=x_grid[:, 1])
)

x_grid_ext = np.asarray(x_grid_ext)

# Generate model predictions on the grid.
pm.set_data({&quot;data&quot;: x_grid_ext}, model=model)
ppc_grid = pm.sample_posterior_predictive(trace, model=model, samples=1000)</code></pre>
<p>Now we compute the model decision boundary on the grid for visualization purposes.</p>
<pre class="python"><code>numerator = -(trace[&quot;Intercept&quot;].mean(axis=0) + trace[&quot;x1&quot;].mean(axis=0) * x1_grid)
denominator = trace[&quot;x2&quot;].mean(axis=0) + trace[&quot;x1:x2&quot;].mean(axis=0) * x1_grid
bd_grid = numerator / denominator

grid_df = pd.DataFrame(x_grid, columns=[&quot;x1&quot;, &quot;x2&quot;])
grid_df[&quot;p&quot;] = ppc_grid[&quot;y&quot;].mean(axis=0)
grid_df.sort_values(&quot;p&quot;, inplace=True)

p_grid = grid_df.pivot(index=&quot;x2&quot;, columns=&quot;x1&quot;, values=&quot;p&quot;).to_numpy()</code></pre>
<p>We finally get the plot and the predictions on the test set:</p>
<pre class="python"><code>fig, ax = plt.subplots()
cmap = sns.diverging_palette(240, 10, n=50, as_cmap=True)
sns.scatterplot(
    x=x_test[:, 1].flatten(),
    y=x_test[:, 2].flatten(),
    hue=y_test,
    palette=[sns_c_div[0], sns_c_div[-1]],
    ax=ax,
)
sns.lineplot(x=x1_grid, y=bd_grid, color=&quot;black&quot;, ax=ax)
ax.contourf(x1_grid, x2_grid, p_grid, cmap=cmap, alpha=0.3)
ax.legend(title=&quot;y&quot;, loc=&quot;center left&quot;, bbox_to_anchor=(1, 0.5))
ax.lines[0].set_linestyle(&quot;dotted&quot;)
ax.set(
  title=&quot;Model Decision Boundary&quot;,
  xlim=(-9, 9),
  ylim=(-9, 9),
  xlabel=&quot;x1&quot;,
  ylabel=&quot;x2&quot;
);</code></pre>
<center>
<div class="figure">
<img src="../images/glm_pymc3_files/glm_pymc3_48_0.svg" alt="" />
<p class="caption">svg</p>
</div>
</center>
<p><strong>Remark:</strong> Note that we have computed the model decision boundary by using the mean of the posterior samples. However, we can generate a better (and more informative!) plot if we use the complete distribution (similarly for other metrics like accuracy and auc). One way of doing this is by storing and computing it inside the model definition as a <code>Deterministic</code> variable as in <a href="https://github.com/aloctavodia/BAP/blob/master/code/Chp4/04_Generalizing_linear_models.ipynb">Bayesian Analysis with Python (Second edition) - Chapter 4</a>.</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/yaml.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/dockerfile.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'G-5NM5EDH834', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

