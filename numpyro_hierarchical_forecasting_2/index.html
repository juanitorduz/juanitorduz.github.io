<!DOCTYPE html>
<html lang="en-us">
  <head>
    <script defer src="https://use.fontawesome.com/releases/v6.5.1/js/all.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-5NM5EDH834"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5NM5EDH834');
</script>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.1" />


<title>From Pyro to NumPyro: Forecasting Hierarchical Models - Part II - Dr. Juan Camilo Orduz</title>
<meta property="og:title" content="From Pyro to NumPyro: Forecasting Hierarchical Models - Part II - Dr. Juan Camilo Orduz">


  <link href='../images/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/tattoo_logo.jpg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../about/"> About</a></li>
    
    <li><a href="https://github.com/juanitorduz"><i class='fab fa-github fa-2x'></i>  </a></li>
    
    <li><a href="https://www.linkedin.com/in/juanitorduz/"><i class='fab fa-linkedin fa-2x' style='color:#0a66c2;'></i>  </a></li>
    
    <li><a href="https://twitter.com/juanitorduz"><i class='fab fa-twitter fa-2x' style='color:#1DA1F2;'></i>  </a></li>
    
    <li><a href="https://bayes.club/@juanitorduz"><i class='fab fa-mastodon fa-2x' style='color:#6364FF;'></i>  </a></li>
    
    <li><a href="https://ko-fi.com/juanitorduz"><i class='fa-solid fa-mug-hot fa-2x' style='color:#FF5E5B;'></i>  </a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">8 min read</span>
    

    <h1 class="article-title">From Pyro to NumPyro: Forecasting Hierarchical Models - Part II</h1>

    
    <span class="article-date">2024-10-03</span>
    

    <div class="article-content">
      


<p>In this second notebook, we continue working on the NumPyro implementation of the hierarchical forecasting models presented in Pyroâ€™s forecasting documentation: <a href="https://pyro.ai/examples/forecasting_iii.html">Forecasting III: hierarchical models</a>. In this second part, we extend the model described in the first part <a href="https://juanitorduz.github.io/numpyro_hierarchical_forecasting_1/">From Pyro to NumPyro: Forecasting Hierarchical Models - Part I</a> by adding all stations to the model.</p>
<div id="prepare-notebook" class="section level2">
<h2>Prepare Notebook</h2>
<pre class="python"><code>import arviz as az
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt
import numpyro
import numpyro.distributions as dist
from jax import random
from jaxtyping import Array, Float
from numpyro.contrib.control_flow import scan
from numpyro.infer import SVI, Predictive, Trace_ELBO
from numpyro.infer.autoguide import AutoNormal
from numpyro.infer.reparam import LocScaleReparam
from pyro.contrib.examples.bart import load_bart_od

az.style.use(&quot;arviz-darkgrid&quot;)
plt.rcParams[&quot;figure.figsize&quot;] = [12, 7]
plt.rcParams[&quot;figure.dpi&quot;] = 100
plt.rcParams[&quot;figure.facecolor&quot;] = &quot;white&quot;

numpyro.set_host_device_count(n=4)

rng_key = random.PRNGKey(seed=42)

%load_ext autoreload
%autoreload 2
%load_ext jaxtyping
%jaxtyping.typechecker beartype.beartype
%config InlineBackend.figure_format = &quot;retina&quot;</code></pre>
<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
The jaxtyping extension is already loaded. To reload it, use:
  %reload_ext jaxtyping</code></pre>
</div>
<div id="read-data" class="section level2">
<h2>Read Data</h2>
<pre class="python"><code>dataset = load_bart_od()
print(dataset.keys())
print(dataset[&quot;counts&quot;].shape)
print(&quot; &quot;.join(dataset[&quot;stations&quot;]))</code></pre>
<pre><code>dict_keys([&#39;stations&#39;, &#39;start_date&#39;, &#39;counts&#39;])
torch.Size([78888, 50, 50])
12TH 16TH 19TH 24TH ANTC ASHB BALB BAYF BERY CAST CIVC COLM COLS CONC DALY DBRK DELN DUBL EMBR FRMT FTVL GLEN HAYW LAFY LAKE MCAR MLBR MLPT MONT NBRK NCON OAKL ORIN PCTR PHIL PITT PLZA POWL RICH ROCK SANL SBRN SFIA SHAY SSAN UCTY WARM WCRK WDUB WOAK</code></pre>
<p>In this second example, we model all the rides from all stations to all other stations.</p>
<pre class="python"><code>data = dataset[&quot;counts&quot;].permute(1, 2, 0).log1p()
T = data.shape[-2]
print(data.shape)</code></pre>
<pre><code>torch.Size([50, 50, 78888])</code></pre>
</div>
<div id="train---test-split" class="section level2">
<h2>Train - Test Split</h2>
<p>Similarly as in the first example, for training purposes we will use data from 90 days before the test data.</p>
<pre class="python"><code>T2 = data.size(-1)  # end
T1 = T2 - 24 * 7 * 2  # train/test split
T0 = T1 - 24 * 90  # beginning: train on 90 days of data</code></pre>
<pre class="python"><code>y = jnp.array(data[..., T0:T2])
y_train = jnp.array(data[..., T0:T1])
y_test = jnp.array(data[..., T1:T2])

print(f&quot;y: {y.shape}&quot;)
print(f&quot;y_train: {y_train.shape}&quot;)
print(f&quot;y_test: {y_test.shape}&quot;)</code></pre>
<pre><code>y: (50, 50, 2496)
y_train: (50, 50, 2160)
y_test: (50, 50, 336)</code></pre>
<pre class="python"><code>n_stations = y_train.shape[-2]

time = jnp.array(range(T0, T2))
time_train = jnp.array(range(T0, T1))
t_max_train = time_train.size

time_test = jnp.array(range(T1, T2))
t_max_test = time_test.size

covariates = jnp.zeros_like(y)
covariates_train = jnp.zeros_like(y_train)
covariates_test = jnp.zeros_like(y_test)

assert time_train.size + time_test.size == time.size
assert y_train.shape == (n_stations, n_stations, t_max_train)
assert y_test.shape == (n_stations, n_stations, t_max_test)
assert covariates.shape == y.shape
assert covariates_train.shape == y_train.shape
assert covariates_test.shape == y_test.shape</code></pre>
</div>
<div id="repeating-seasonal-features" class="section level2">
<h2>Repeating Seasonal Features</h2>
<p>We also need the JAX version of the <a href="https://docs.pyro.ai/en/stable/ops.html#pyro.ops.tensor_utils.periodic_repeat"><code>periodic_repeat</code></a> function.</p>
<pre class="python"><code>def periodic_repeat_jax(tensor: Array, size: int, dim: int) -&gt; Array:
    &quot;&quot;&quot;
    Repeat a period-sized tensor up to given size using JAX.

    Parameters
    ----------
    tensor : Array
        A JAX array to be repeated.
    size : int
        Desired size of the result along dimension `dim`.
    dim : int
        The tensor dimension along which to repeat.

    Returns
    -------
    Array
        The repeated tensor.

    References
    ----------
    Thttps://docs.pyro.ai/en/stable/ops.html#pyro.ops.tensor_utils.periodic_repeat
    &quot;&quot;&quot;
    assert isinstance(size, int) and size &gt;= 0
    assert isinstance(dim, int)
    if dim &gt;= 0:
        dim -= tensor.ndim

    period = tensor.shape[dim]
    repeats = [1] * tensor.ndim
    repeats[dim] = (size + period - 1) // period
    result = jnp.tile(tensor, repeats)

    slices = [slice(None)] * tensor.ndim
    slices[dim] = slice(None, size)

    return result[tuple(slices)]</code></pre>
</div>
<div id="model-specification" class="section level2">
<h2>Model Specification</h2>
<p>In this model, the local level dynamic is driven by the destination station. On the other hand, the seasonal components and the noise scales come as a sum of the origin and destination stations. The model structure is very similar to the one presented in the first example.</p>
<pre class="python"><code>def model(
    covariates: Float[Array, &quot;n_series n_series t_max&quot;],
    y: Float[Array, &quot;n_series n_series t_max&quot;] | None = None,
) -&gt; None:
    # Get the time and feature dimensions
    n_series, n_series, t_max = covariates.shape

    # Define the plates to be able to use them below
    origin_plate = numpyro.plate(&quot;origin&quot;, n_series, dim=-3)
    destin_plate = numpyro.plate(&quot;destin&quot;, n_series, dim=-2)
    hour_of_week_plate = numpyro.plate(&quot;hour_of_week&quot;, 24 * 7, dim=-1)

    # Global scale for the drift
    drift_scale = numpyro.sample(&quot;drift_scale&quot;, dist.LogNormal(loc=-20, scale=5))

    # Sample the centered parameter for the LocScaleReparam
    destin_centered = numpyro.sample(&quot;destin_centered&quot;, dist.Uniform(low=0, high=1))

    with origin_plate, hour_of_week_plate:
        origin_seasonal = numpyro.sample(&quot;origin_seasonal&quot;, dist.Normal(loc=0, scale=5))

    with destin_plate:
        with (
            numpyro.plate(&quot;time&quot;, t_max),
            numpyro.handlers.reparam(
                config={&quot;drift&quot;: LocScaleReparam(centered=destin_centered)}
            ),
        ):
            # Sample the drift parameters
            # We have one drift parameter per time series (station) and time point
            drift = numpyro.sample(&quot;drift&quot;, dist.Normal(loc=0, scale=drift_scale))

        with hour_of_week_plate:
            # Sample the seasonal parameters
            # We have one seasonal parameter per hour of the week and per station
            destin_seasonal = numpyro.sample(
                &quot;destin_seasonal&quot;, dist.Normal(loc=0, scale=5)
            )

    # We model a static pairwise station-&gt;station affinity, which e.g.
    # can compensate for the fact that people tend not to travel from
    # a station to itself.
    with origin_plate, destin_plate:
        pairwise = numpyro.sample(&quot;pairwise&quot;, dist.Normal(0, 1))

    # We model the origin and destination scales separately
    # and then add them together to get the final scale.
    with origin_plate:
        origin_scale = numpyro.sample(&quot;origin_scale&quot;, dist.LogNormal(-5, 5))
    with destin_plate:
        destin_scale = numpyro.sample(&quot;destin_scale&quot;, dist.LogNormal(-5, 5))
        scale = origin_scale + destin_scale

    # Repeat the seasonal parameters to match the length of the time series
    seasonal = origin_seasonal + destin_seasonal
    seasonal_repeat = periodic_repeat_jax(seasonal, t_max, dim=-1)

    # Define the local level transition function
    def transition_fn(carry, t):
        &quot;Local level transition function&quot;
        previous_level = carry
        current_level = previous_level + drift[..., t]
        return current_level, current_level

    # Compute the latent levels using scan
    _, pred_levels = scan(
        transition_fn, init=jnp.zeros((n_series,)), xs=jnp.arange(t_max)
    )

    # We need to transpose the prediction levels to match the shape of the data
    pred_levels = pred_levels.transpose(1, 0)

    # Compute the mean of the model
    mu = pred_levels + seasonal_repeat + pairwise

    # Sample the observations
    with numpyro.handlers.condition(data={&quot;obs&quot;: y}):
        numpyro.sample(&quot;obs&quot;, dist.Normal(loc=mu, scale=scale))</code></pre>
<p>We can now visualize the model structure.</p>
<pre class="python"><code>numpyro.render_model(
    model=model,
    model_kwargs={&quot;covariates&quot;: covariates_train, &quot;y&quot;: y_train},
    render_distributions=True,
    render_params=True,
)</code></pre>
<center>
<img src="../images/numpyro_hierarchical_forecasting_2_files/numpyro_hierarchical_forecasting_2_16_0.svg" style="width: 900px;"/>
</center>
</div>
<div id="prior-predictive-checks" class="section level2">
<h2>Prior Predictive Checks</h2>
<p>As usual (highly recommended!), we should perform prior predictive checks.</p>
<pre class="python"><code>prior_predictive = Predictive(model=model, num_samples=500, return_sites=[&quot;obs&quot;])

rng_key, rng_subkey = random.split(rng_key)

prior_samples = prior_predictive(rng_subkey, covariates_train)

idata_prior = az.from_dict(
    prior_predictive={k: v[None, ...] for k, v in prior_samples.items()},
    coords={
        &quot;time_train&quot;: time_train,
        &quot;origin&quot;: dataset[&quot;stations&quot;],
        &quot;destin&quot;: dataset[&quot;stations&quot;],
    },
    dims={&quot;obs&quot;: [&quot;origin&quot;, &quot;destin&quot;, &quot;time_train&quot;]},
)</code></pre>
<p>Letâ€™s plot the prior predictive distribution for the first <span class="math inline">\(8\)</span> stations for the destination station <code>ANTC</code>.</p>
<pre class="python"><code>station = &quot;ANTC&quot;
idx = dataset[&quot;stations&quot;].index(station)

fig, axes = plt.subplots(
    nrows=8, ncols=1, figsize=(15, 18), sharex=True, sharey=True, layout=&quot;constrained&quot;
)
for i, ax in enumerate(axes):
    for j, hdi_prob in enumerate([0.94, 0.5]):
        az.plot_hdi(
            time_train[time_train &gt;= T1 - 3 * (24 * 7)],
            idata_prior[&quot;prior_predictive&quot;][&quot;obs&quot;]
            .sel(destin=station)
            .isel(origin=i)[:, :, time_train &gt;= T1 - 3 * (24 * 7)]
            .clip(min=0),
            hdi_prob=hdi_prob,
            color=&quot;C0&quot;,
            fill_kwargs={
                &quot;alpha&quot;: 0.3 + 0.2 * j,
                &quot;label&quot;: f&quot;{hdi_prob*100:.0f}% HDI (train)&quot;,
            },
            smooth=False,
            ax=ax,
        )

    ax.plot(
        time_train[time_train &gt;= T1 - 3 * (24 * 7)],
        data[i, idx, T1 - 3 * (24 * 7) : T1],
        &quot;black&quot;,
        lw=1,
        label=&quot;Truth&quot;,
    )

    ax.legend(
        bbox_to_anchor=(1.05, 1), loc=&quot;upper left&quot;, borderaxespad=0.0, fontsize=12
    )

fig.suptitle(&quot;Prior predictive checks&quot;, fontsize=18, fontweight=&quot;bold&quot;);</code></pre>
<center>
<img src="../images/numpyro_hierarchical_forecasting_2_files/numpyro_hierarchical_forecasting_2_20_0.png" style="width: 1000px;"/>
</center>
<p>Overall, the prior ranges look very reasonable (even too wide).</p>
</div>
<div id="inference-with-svi" class="section level2">
<h2>Inference with SVI</h2>
<p>We now fit the model to the data using stochastic variational inference. This time the model runs for longer as compared to the first one (<span class="math inline">\(45\)</span> seconds to <span class="math inline">\(3.5\)</span> minutes).</p>
<pre class="python"><code>%%time

guide = AutoNormal(model)
optimizer = numpyro.optim.Adam(step_size=0.1)
svi = SVI(model, guide, optimizer, loss=Trace_ELBO())
num_steps = 10_000

rng_key, rng_subkey = random.split(key=rng_key)

svi_result = svi.run(
    rng_subkey,
    num_steps,
    covariates_train,
    y_train,
)

fig, ax = plt.subplots(figsize=(9, 6))
ax.plot(svi_result.losses)
ax.set_yscale(&quot;log&quot;)
ax.set_title(&quot;ELBO loss&quot;, fontsize=18, fontweight=&quot;bold&quot;);</code></pre>
<pre><code>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [03:23&lt;00:00, 49.10it/s, init loss: 1727067648.0000, avg. loss [9501-10000]: 3742141.6960]


CPU times: user 9min 45s, sys: 1min 46s, total: 11min 31s
Wall time: 3min 28s</code></pre>
<center>
<img src="../images/numpyro_hierarchical_forecasting_2_files/numpyro_hierarchical_forecasting_2_23_2.png" style="width: 700px;"/>
</center>
<p>The resulting ELBO loss good!</p>
</div>
<div id="posterior-predictive-check" class="section level2">
<h2>Posterior Predictive Check</h2>
<p>Next, we generate posterior predictive samples for the forecast for each of the stations pairs.</p>
<pre class="python"><code>posterior = Predictive(
    model=model,
    guide=guide,
    params=svi_result.params,
    num_samples=200,
    return_sites=[&quot;obs&quot;],
)</code></pre>
<pre class="python"><code>rng_key, rng_subkey = random.split(rng_key)

idata_train = az.from_dict(
    posterior_predictive={
        k: v[None, ...] for k, v in posterior(rng_subkey, covariates_train).items()
    },
    coords={
        &quot;time_train&quot;: time_train,
        &quot;origin&quot;: dataset[&quot;stations&quot;],
        &quot;destin&quot;: dataset[&quot;stations&quot;],
    },
    dims={&quot;obs&quot;: [&quot;origin&quot;, &quot;destin&quot;, &quot;time_train&quot;]},
)

idata_test = az.from_dict(
    posterior_predictive={
        k: v[None, ...] for k, v in posterior(rng_subkey, covariates).items()
    },
    coords={
        &quot;time&quot;: time,
        &quot;origin&quot;: dataset[&quot;stations&quot;],
        &quot;destin&quot;: dataset[&quot;stations&quot;],
    },
    dims={&quot;obs&quot;: [&quot;origin&quot;, &quot;destin&quot;, &quot;time&quot;]},
)</code></pre>
<p>To evaluate the model performance,we compute the CRPS for the training and test data. For comparison purposes, we clip the data to ensure the predictions are non-negative.</p>
<pre class="python"><code>@jax.jit
def crps(
    truth: Float[Array, &quot;n_series n_series t_max&quot;],
    pred: Float[Array, &quot;n_samples n_series n_series t_max&quot;],
    sample_weight: Float[Array, &quot; t_max&quot;] | None = None,
) -&gt; Float[Array, &quot;&quot;]:
    if pred.shape[1:] != (1,) * (pred.ndim - truth.ndim - 1) + truth.shape:
        raise ValueError(
            f&quot;&quot;&quot;Expected pred to have one extra sample dim on left.
            Actual shapes: {pred.shape} versus {truth.shape}&quot;&quot;&quot;
        )

    absolute_error = jnp.mean(jnp.abs(pred - truth), axis=0)

    num_samples = pred.shape[0]
    if num_samples == 1:
        return jnp.average(absolute_error, weights=sample_weight)

    pred = jnp.sort(pred, axis=0)
    diff = pred[1:] - pred[:-1]
    weight = jnp.arange(1, num_samples) * jnp.arange(num_samples - 1, 0, -1)
    weight = weight.reshape(weight.shape + (1,) * (diff.ndim - 1))

    per_obs_crps = absolute_error - jnp.sum(diff * weight, axis=0) / num_samples**2
    return jnp.average(per_obs_crps, weights=sample_weight)


crps_train = crps(
    y_train,
    jnp.array(idata_train[&quot;posterior_predictive&quot;][&quot;obs&quot;].sel(chain=0).clip(min=0)),
)

crps_test = crps(
    y_test,
    jnp.array(
        idata_test[&quot;posterior_predictive&quot;][&quot;obs&quot;]
        .sel(chain=0)
        .sel(time=slice(T1, T2))
        .clip(min=0)
    ),
)</code></pre>
<p>Finally, we reproduce the model fit and plot from the Pyro example.</p>
<pre class="python"><code>station = &quot;ANTC&quot;
idx = dataset[&quot;stations&quot;].index(station)

fig, axes = plt.subplots(
    nrows=8, ncols=1, figsize=(15, 18), sharex=True, sharey=True, layout=&quot;constrained&quot;
)
for i, ax in enumerate(axes):
    for j, hdi_prob in enumerate([0.94, 0.5]):
        az.plot_hdi(
            time_train[time_train &gt;= T1 - 24 * 7],
            idata_train[&quot;posterior_predictive&quot;][&quot;obs&quot;]
            .sel(destin=station)
            .isel(origin=i)[:, :, time_train &gt;= T1 - 24 * 7]
            .clip(min=0),
            hdi_prob=hdi_prob,
            color=&quot;C0&quot;,
            fill_kwargs={
                &quot;alpha&quot;: 0.3 + 0.2 * j,
                &quot;label&quot;: f&quot;{hdi_prob*100:.0f}% HDI (train)&quot;,
            },
            smooth=False,
            ax=ax,
        )

        az.plot_hdi(
            time[time &gt;= T1],
            idata_test[&quot;posterior_predictive&quot;][&quot;obs&quot;]
            .sel(destin=station)
            .isel(origin=i)[:, :, time &gt;= T1]
            .clip(min=0),
            hdi_prob=hdi_prob,
            color=&quot;C1&quot;,
            fill_kwargs={
                &quot;alpha&quot;: 0.2 + 0.2 * j,
                &quot;label&quot;: f&quot;{hdi_prob*100:.0f}% HDI (test)&quot;,
            },
            smooth=False,
            ax=ax,
        )

    ax.plot(
        time[time &gt;= T1 - 24 * 7],
        data[i, idx, T1 - 24 * 7 : T2],
        &quot;black&quot;,
        lw=1,
        label=&quot;Truth&quot;,
    )

    ax.axvline(T1, color=&quot;C3&quot;, linestyle=&quot;--&quot;, label=&quot;Train/test split&quot;)

    ax.legend(
        bbox_to_anchor=(1.05, 1), loc=&quot;upper left&quot;, borderaxespad=0.0, fontsize=12
    )

fig.suptitle(
    f&quot;&quot;&quot;Posterior predictive checks

    Train CRPS: {crps_train:.4f} | Test CRPS: {crps_test:.4f}
    &quot;&quot;&quot;,
    fontsize=18,
    fontweight=&quot;bold&quot;,
);</code></pre>
<center>
<img src="../images/numpyro_hierarchical_forecasting_2_files/numpyro_hierarchical_forecasting_2_31_0.png" style="width: 1000px;"/>
</center>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/yaml.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/dockerfile.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'G-5NM5EDH834', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

