<!DOCTYPE html>
<html lang="en-us">
  <head>
    <script defer src="https://use.fontawesome.com/releases/v6.5.1/js/all.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-5NM5EDH834"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5NM5EDH834');
</script>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.1" />


<title>Time-Varying Regression Coefficients via Gaussian Random Walk in PyMC - Dr. Juan Camilo Orduz</title>
<meta property="og:title" content="Time-Varying Regression Coefficients via Gaussian Random Walk in PyMC - Dr. Juan Camilo Orduz">


  <link href='../images/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/tattoo_logo.jpg"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../about/"> About</a></li>
    
    <li><a href="https://github.com/juanitorduz"><i class='fab fa-github fa-2x'></i>  </a></li>
    
    <li><a href="https://www.linkedin.com/in/juanitorduz/"><i class='fab fa-linkedin fa-2x' style='color:#0a66c2;'></i>  </a></li>
    
    <li><a href="https://twitter.com/juanitorduz"><i class='fab fa-twitter fa-2x' style='color:#1DA1F2;'></i>  </a></li>
    
    <li><a href="https://bayes.club/@juanitorduz"><i class='fab fa-mastodon fa-2x' style='color:#6364FF;'></i>  </a></li>
    
    <li><a href="https://ko-fi.com/juanitorduz"><i class='fa-solid fa-mug-hot fa-2x' style='color:#FF5E5B;'></i>  </a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">14 min read</span>
    

    <h1 class="article-title">Time-Varying Regression Coefficients via Gaussian Random Walk in PyMC</h1>

    
    <span class="article-date">2022-07-03</span>
    

    <div class="article-content">
      


<p>In this notebook we want to illustrate how to use PyMC to fit a time-varying coefficient regression model. The motivation comes from post <a href="https://juanitorduz.github.io/interpretable_ml/">Exploring Tools for Interpretable Machine Learning</a> where we studied a time series problem, regarding the <a href="https://christophm.github.io/interpretable-ml-book/bike-data.html">prediction of the number of bike rentals</a>, from a machine learning perspective. Concretely, we fitted and compared two machine learning models: a linear regression with interactions and a gradient boost model (XGBoost). The models regressors were mainly meteorological data and seasonality features. One interesting feature we saw, through <a href="https://christophm.github.io/interpretable-ml-book/pdp.html">PDP</a> and <a href="https://christophm.github.io/interpretable-ml-book/ice.html">ICE</a> plots was that the temperature feature had a non-constant effect over the bike rentals (see <a href="https://christophm.github.io/interpretable-ml-book/ice.html#examples-4">here</a>). Indeed, when the temperature is high (more than 25 degrees approximately), the bike rentals are negatively impacted by the temperature (to be fair, this is when controlling by other regressors) on average. What we want to do in this notebook is to tackle the same problem from a different perspective. Namely, use to use a <a href="https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.GaussianRandomWalk.html">GaussianRandomWalk</a> to model the interaction effect between the temperature and the bike rentals. We of course start with the simple regression baseline for comparison.</p>
<div id="prepare-notebook" class="section level2">
<h2>Prepare Notebook</h2>
<pre class="python"><code>import arviz as az
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pymc as pm
from pymc.distributions.continuous import Exponential
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns


plt.style.use(&quot;bmh&quot;)
plt.rcParams[&quot;figure.figsize&quot;] = [10, 6]
plt.rcParams[&quot;figure.dpi&quot;] = 100
plt.rcParams[&quot;figure.facecolor&quot;] = &quot;white&quot;

%load_ext autoreload
%autoreload 2
%config InlineBackend.figure_format = &quot;retina&quot;</code></pre>
<pre class="python"><code>seed: int = sum(map(ord, &quot;bikes&quot;))
rng: np.random.Generator = np.random.default_rng(seed=seed)</code></pre>
</div>
<div id="read-data" class="section level2">
<h2>Read Data</h2>
<p>For a detailed description of the data set please see <a href="https://christophm.github.io/interpretable-ml-book/bike-data.html">here</a> (from the book <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning:A Guide for Making Black Box Models Explainable by Christoph Molnar</a>). For a detailed EDA see the previous post <a href="https://juanitorduz.github.io/interpretable_ml/">Exploring Tools for Interpretable Machine Learning</a>.</p>
<pre class="python"><code>data_path = &quot;https://raw.githubusercontent.com/christophM/interpretable-ml-book/master/data/bike.csv&quot;

raw_data_df = pd.read_csv(
    data_path,
    dtype={
        &quot;season&quot;: &quot;category&quot;,
        &quot;mnth&quot;: &quot;category&quot;,
        &quot;holiday&quot;: &quot;category&quot;,
        &quot;weekday&quot;: &quot;category&quot;,
        &quot;workingday&quot;: &quot;category&quot;,
        &quot;weathersit&quot;: &quot;category&quot;,
        &quot;cnt&quot;: &quot;int&quot;,
    },
)

raw_data_df.head()
</code></pre>
<center>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
        font-size: 15px;
    }

    .dataframe thead th {
        text-align: left;
        font-size: 15px;
    }

    .dataframe tbody tr th {
        vertical-align: top;
        font-size: 15px;
    }
    
    .dataframe tbody tr td {
        vertical-align: top;
        font-size: 15px;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
season
</th>
<th>
yr
</th>
<th>
mnth
</th>
<th>
holiday
</th>
<th>
weekday
</th>
<th>
workingday
</th>
<th>
weathersit
</th>
<th>
temp
</th>
<th>
hum
</th>
<th>
windspeed
</th>
<th>
cnt
</th>
<th>
days_since_2011
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
WINTER
</td>
<td>
2011
</td>
<td>
JAN
</td>
<td>
NO HOLIDAY
</td>
<td>
SAT
</td>
<td>
NO WORKING DAY
</td>
<td>
MISTY
</td>
<td>
8.175849
</td>
<td>
80.5833
</td>
<td>
10.749882
</td>
<td>
985
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
WINTER
</td>
<td>
2011
</td>
<td>
JAN
</td>
<td>
NO HOLIDAY
</td>
<td>
SUN
</td>
<td>
NO WORKING DAY
</td>
<td>
MISTY
</td>
<td>
9.083466
</td>
<td>
69.6087
</td>
<td>
16.652113
</td>
<td>
801
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
WINTER
</td>
<td>
2011
</td>
<td>
JAN
</td>
<td>
NO HOLIDAY
</td>
<td>
MON
</td>
<td>
WORKING DAY
</td>
<td>
GOOD
</td>
<td>
1.229108
</td>
<td>
43.7273
</td>
<td>
16.636703
</td>
<td>
1349
</td>
<td>
2
</td>
</tr>
<tr>
<th>
3
</th>
<td>
WINTER
</td>
<td>
2011
</td>
<td>
JAN
</td>
<td>
NO HOLIDAY
</td>
<td>
TUE
</td>
<td>
WORKING DAY
</td>
<td>
GOOD
</td>
<td>
1.400000
</td>
<td>
59.0435
</td>
<td>
10.739832
</td>
<td>
1562
</td>
<td>
3
</td>
</tr>
<tr>
<th>
4
</th>
<td>
WINTER
</td>
<td>
2011
</td>
<td>
JAN
</td>
<td>
NO HOLIDAY
</td>
<td>
WED
</td>
<td>
WORKING DAY
</td>
<td>
GOOD
</td>
<td>
2.666979
</td>
<td>
43.6957
</td>
<td>
12.522300
</td>
<td>
1600
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
</div>
<center>
</div>
<div id="data-formatting" class="section level2">
<h2>Data Formatting</h2>
<pre class="python"><code>data_df = raw_data_df.copy()

data_df[&quot;date&quot;] = pd.to_datetime(&quot;2011-01-01&quot;) + data_df[&quot;days_since_2011&quot;].apply(
    lambda z: pd.Timedelta(z, unit=&quot;D&quot;)
)

data_df.info()</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 731 entries, 0 to 730
Data columns (total 13 columns):
 #   Column           Non-Null Count  Dtype         
---  ------           --------------  -----         
 0   season           731 non-null    category      
 1   yr               731 non-null    int64         
 2   mnth             731 non-null    category      
 3   holiday          731 non-null    category      
 4   weekday          731 non-null    category      
 5   workingday       731 non-null    category      
 6   weathersit       731 non-null    category      
 7   temp             731 non-null    float64       
 8   hum              731 non-null    float64       
 9   windspeed        731 non-null    float64       
 10  cnt              731 non-null    int64         
 11  days_since_2011  731 non-null    int64         
 12  date             731 non-null    datetime64[ns]
dtypes: category(6), datetime64[ns](1), float64(3), int64(3)
memory usage: 45.6 KB</code></pre>
<p>Letâ€™s plot the time development of the bike rentals and temperature over time.</p>
<pre class="python"><code>fig, ax = plt.subplots(
    nrows=2, ncols=1, figsize=(10, 6), sharex=True, sharey=False, layout=&quot;constrained&quot;
)
sns.lineplot(x=&quot;date&quot;, y=&quot;cnt&quot;, data=data_df, color=&quot;black&quot;, ax=ax[0])
sns.lineplot(x=&quot;date&quot;, y=&quot;temp&quot;, data=data_df, color=&quot;C0&quot;, ax=ax[1])
ax[0].set(title=&quot;Count of bikes&quot;)
ax[1].set(title=&quot;Temperature&quot;)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_8_1.png" style="width: 1000px;"/>
</center>
<p>We add a Gaussian <a href="https://juanitorduz.github.io/bump_func/">bump function</a> to model the end-of-year seasonality.</p>
<pre class="python"><code>is_december = data_df[&quot;date&quot;].dt.month == 12
eoy_mu = 25
eoy_sigma = 7
eoy_arg = (data_df[&quot;date&quot;].dt.day - eoy_mu) / eoy_sigma
data_df[&quot;eoy&quot;] = is_december * np.exp(-(eoy_arg**2))

fig, ax = plt.subplots()
sns.lineplot(x=&quot;date&quot;, y=&quot;eoy&quot;, data=data_df, color=&quot;C4&quot;, ax=ax)
ax.set(title=&quot;End-of-Year Gaussian Bump&quot;)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_10_1.png" style="width: 900px;"/>
</center>
<p>As we are going to fit a linear model is always good to scale the data.</p>
<pre class="python"><code>target = &quot;cnt&quot;
target_scaled = f&quot;{target}_scaled&quot;

endog_scaler = MinMaxScaler()
exog_scaler = MinMaxScaler()


data_df[target_scaled] = endog_scaler.fit_transform(X=data_df[[target]])
data_df[[&quot;temp_scaled&quot;, &quot;hum_scaled&quot;, &quot;windspeed_scaled&quot;]] = exog_scaler.fit_transform(
    X=data_df[[&quot;temp&quot;, &quot;hum&quot;, &quot;windspeed&quot;]]
)</code></pre>
<p>Finally, we extract the features we want to include in the model.</p>
<pre class="python"><code>n = data_df.shape[0]
# target
cnt = data_df[target].to_numpy()
cnt_scaled = data_df[target_scaled].to_numpy()
# date feature
date = data_df[&quot;date&quot;].to_numpy()
# model regressors
temp_scaled = data_df[&quot;temp_scaled&quot;].to_numpy()
hum_scaled = data_df[&quot;hum_scaled&quot;].to_numpy()
windspeed_scaled = data_df[&quot;windspeed_scaled&quot;].to_numpy()
holiday_idx, holiday = data_df[&quot;holiday&quot;].factorize(sort=True)
workingday_idx, workingday = data_df[&quot;workingday&quot;].factorize(sort=True)
weathersit_idx, weathersit = data_df[&quot;weathersit&quot;].factorize(sort=True)
t = data_df[&quot;days_since_2011&quot;].to_numpy() / data_df[&quot;days_since_2011&quot;].max()
eoy = data_df[&quot;eoy&quot;].to_numpy()</code></pre>
</div>
<div id="base-model" class="section level2">
<h2>Base Model</h2>
<p>Before we jump into the time-varying coefficient model let us fist fit a baseline regression model. Let us follow the <a href="https://arxiv.org/abs/2011.01808">bayesian workflow</a> for model development.</p>
<div id="model-specification" class="section level3">
<h3>1. Model Specification</h3>
<p>In a first step (after EDA and data pre-processing) we define the model structure. In particular we choose</p>
<ol style="list-style-type: decimal">
<li><strong>Prior</strong> distributions for the regression coefficients and the noise.</li>
<li><strong>Model parametrization</strong>, i.e.Â the structure of the linear model. Note that for the categorical variables we use a <a href="https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.ZeroSumNormal.html"><code>ZeroSumNormal</code></a> since we are adding an intercept term.</li>
<li><strong>Likelihood function</strong>, which is this case we decide for a <a href="https://docs.pymc.io/en/latest/api/distributions/generated/pymc.StudentT.html">StudentT</a> distribution.</li>
</ol>
<pre class="python"><code>coords = {
    &quot;date&quot;: date,
    &quot;workingday&quot;: workingday,
    &quot;weathersit&quot;: weathersit,
}

with pm.Model(coords=coords) as base_model:
    # --- priors ---
    intercept = pm.Normal(name=&quot;intercept&quot;, mu=0, sigma=2)
    b_temp = pm.Normal(name=&quot;b_temp&quot;, mu=0, sigma=1)
    b_hum = pm.Normal(name=&quot;b_hum&quot;, mu=0, sigma=1)
    b_windspeed = pm.Normal(name=&quot;b_windspeed&quot;, mu=0, sigma=1)
    b_holiday = pm.ZeroSumNormal(name=&quot;b_holiday&quot;, sigma=1, dims=&quot;holiday&quot;)
    b_workingday = pm.ZeroSumNormal(name=&quot;b_workingday&quot;, sigma=1, dims=&quot;workingday&quot;)
    b_weathersit = pm.ZeroSumNormal(name=&quot;b_weathersit&quot;, sigma=1, dims=&quot;weathersit&quot;)
    b_t = pm.Normal(name=&quot;b_t&quot;, mu=0, sigma=3)
    b_eoy = pm.Normal(name=&quot;b_eoy&quot;, mu=0, sigma=1)
    nu = pm.Gamma(name=&quot;nu&quot;, alpha=8, beta=2)
    sigma = pm.HalfNormal(name=&quot;sigma&quot;, sigma=1)

    # --- model parametrization ---
    mu = pm.Deterministic(
        name=&quot;mu&quot;,
        var=(
            intercept
            + b_t * t
            + b_temp * temp_scaled
            + b_hum * hum_scaled
            + b_windspeed * windspeed_scaled
            + b_holiday[holiday_idx]
            + b_workingday[workingday_idx]
            + b_weathersit[weathersit_idx]
            + b_eoy * eoy
        ),
        dims=&quot;date&quot;,
    )

    # --- likelihood ---
    likelihood = pm.StudentT(
        name=&quot;likelihood&quot;, mu=mu, nu=nu, sigma=sigma, dims=&quot;date&quot;, observed=cnt_scaled
    )


pm.model_to_graphviz(base_model)
</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_17_0.svg" style="width: 1000px;"/>
</center>
</div>
<div id="prior-predictive-analysis" class="section level3">
<h3>2. Prior Predictive Analysis</h3>
<p>We can analyze what the model <em>expects</em> before seeing the data.</p>
<pre class="python"><code>with base_model:
    # --- prior samples ---
    prior_predictive_base = pm.sample_prior_predictive(samples=200, random_seed=rng)


palette = &quot;viridis_r&quot;
cmap = plt.get_cmap(palette)
percs = np.linspace(51, 99, 100)
colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))


fig, ax = plt.subplots(figsize=(12, 6))

for i, p in enumerate(percs[::-1]):
    upper = np.percentile(
        prior_predictive_base.prior_predictive[&quot;likelihood&quot;], p, axis=1
    )
    lower = np.percentile(
        prior_predictive_base.prior_predictive[&quot;likelihood&quot;], 100 - p, axis=1
    )
    color_val = colors[i]
    ax.fill_between(
        x=date,
        y1=upper.flatten(),
        y2=lower.flatten(),
        color=cmap(color_val),
        alpha=0.1,
    )
sns.lineplot(x=date, y=cnt_scaled, color=&quot;black&quot;, ax=ax)
ax.set(
    title=&quot;Base Model - Prior Predictive Samples&quot;,
    xlabel=&quot;date&quot;,
    ylabel=target_scaled,
)
</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_19_2.png" style="width: 1000px;"/>
</center>
<p>The chosen prior distributions are not very restrictive but they image of the predictions is still within a reasonable range.</p>
</div>
<div id="model-fit" class="section level3">
<h3>3. Model Fit</h3>
<p>We sample from the posterior distributions using the <a href="https://www.pymc.io/projects/docs/en/latest/api/generated/pymc.sampling_jax.sample_numpyro_nuts.html">JAX based NUTS sampler from Numpyro</a>.</p>
<pre class="python"><code>with base_model:
    idata_base = pm.sample(
        target_accept=0.9,
        draws=2_000,
        chains=5,
        nuts_sampler=&quot;numpyro&quot;,
        idata_kwargs={&quot;log_likelihood&quot;: True},
        random_seed=rng,
    )
    posterior_predictive_base = pm.sample_posterior_predictive(
        trace=idata, random_seed=rng
    )
</code></pre>
<pre class="python"><code># get number of divergences
idata_base[&quot;sample_stats&quot;][&quot;diverging&quot;].sum().item()</code></pre>
<pre><code>0</code></pre>
</div>
<div id="model-diagnostics" class="section level3">
<h3>4. Model Diagnostics</h3>
<p>Now wee look into some diagnostics metrics an plots.</p>
<pre class="python"><code>az.summary(data=idata_base, var_names=[&quot;~mu&quot;])
</code></pre>
<center>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
        font-size: 15px;
    }

    .dataframe thead th {
        text-align: left;
        font-size: 15px;
    }

    .dataframe tbody tr th {
        vertical-align: top;
        font-size: 15px;
    }
    
    .dataframe tbody tr td {
        vertical-align: top;
        font-size: 15px;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
mean
</th>
<th>
sd
</th>
<th>
hdi_3%
</th>
<th>
hdi_97%
</th>
<th>
mcse_mean
</th>
<th>
mcse_sd
</th>
<th>
ess_bulk
</th>
<th>
ess_tail
</th>
<th>
r_hat
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
intercept
</th>
<td>
0.096
</td>
<td>
0.031
</td>
<td>
0.039
</td>
<td>
0.155
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
4774.0
</td>
<td>
5867.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_temp
</th>
<td>
0.474
</td>
<td>
0.016
</td>
<td>
0.442
</td>
<td>
0.503
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
10817.0
</td>
<td>
7829.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_hum
</th>
<td>
-0.155
</td>
<td>
0.032
</td>
<td>
-0.216
</td>
<td>
-0.096
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
6113.0
</td>
<td>
6706.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_windspeed
</th>
<td>
-0.129
</td>
<td>
0.023
</td>
<td>
-0.173
</td>
<td>
-0.085
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
7584.0
</td>
<td>
6548.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_t
</th>
<td>
0.460
</td>
<td>
0.012
</td>
<td>
0.437
</td>
<td>
0.483
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
10465.0
</td>
<td>
7553.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_eoy
</th>
<td>
-0.310
</td>
<td>
0.025
</td>
<td>
-0.357
</td>
<td>
-0.262
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
10741.0
</td>
<td>
7346.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_holiday[HOLIDAY]
</th>
<td>
-0.025
</td>
<td>
0.011
</td>
<td>
-0.045
</td>
<td>
-0.005
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
9671.0
</td>
<td>
7367.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_holiday[NO HOLIDAY]
</th>
<td>
0.025
</td>
<td>
0.011
</td>
<td>
0.005
</td>
<td>
0.045
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
9671.0
</td>
<td>
7367.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_workingday[NO WORKING DAY]
</th>
<td>
-0.007
</td>
<td>
0.004
</td>
<td>
-0.014
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
12154.0
</td>
<td>
7185.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_workingday[WORKING DAY]
</th>
<td>
0.007
</td>
<td>
0.004
</td>
<td>
-0.000
</td>
<td>
0.014
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
12154.0
</td>
<td>
7185.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_weathersit[GOOD]
</th>
<td>
0.086
</td>
<td>
0.009
</td>
<td>
0.068
</td>
<td>
0.103
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
5353.0
</td>
<td>
6721.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_weathersit[MISTY]
</th>
<td>
0.044
</td>
<td>
0.008
</td>
<td>
0.029
</td>
<td>
0.060
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
8161.0
</td>
<td>
7154.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
b_weathersit[RAIN/SNOW/STORM]
</th>
<td>
-0.130
</td>
<td>
0.015
</td>
<td>
-0.160
</td>
<td>
-0.102
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
5753.0
</td>
<td>
6144.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
nu
</th>
<td>
4.816
</td>
<td>
0.812
</td>
<td>
3.363
</td>
<td>
6.345
</td>
<td>
0.009
</td>
<td>
0.006
</td>
<td>
8752.0
</td>
<td>
7263.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
sigma
</th>
<td>
0.077
</td>
<td>
0.003
</td>
<td>
0.070
</td>
<td>
0.084
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
8498.0
</td>
<td>
7483.0
</td>
<td>
1.0
</td>
</tr>
</tbody>
</table>
</div>
</center>
<pre class="python"><code>axes = az.plot_trace(
    data=idata_base,
    var_names=[&quot;~mu&quot;],
    compact=True,
    kind=&quot;rank_bars&quot;,
    backend_kwargs={&quot;figsize&quot;: (12, 15), &quot;layout&quot;: &quot;constrained&quot;},
)
plt.gcf().suptitle(&quot;Base Model - Trace&quot;, fontsize=16)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_26_2.png" style="width: 1000px;"/>
</center>
<p>Overall, the model looks good.</p>
<pre class="python"><code>axes = az.plot_forest(
    data=idata_base,
    var_names=[&quot;~mu&quot;, &quot;~nu&quot;, &quot;~sigma&quot;],
    combined=True,
    r_hat=True,
    ess=True,
    figsize=(10, 6),
)
axes[0].axvline(x=0.0, color=&quot;black&quot;, linestyle=&quot;--&quot;)
plt.gcf().suptitle(&quot;Base Model - Posterior Distributions&quot;, fontsize=16)
</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_28_1.png" style="width: 1000px;"/>
</center>
<p>Note that in this base model the temperature feature has a positive effect on bike rentals on average.</p>
</div>
<div id="posterior-predictive-distribution" class="section level3">
<h3>5. Posterior Predictive Distribution</h3>
<p>Finally, let us take a look at the fitted values.</p>
<pre class="python"><code>palette = &quot;viridis_r&quot;
cmap = plt.get_cmap(palette)
percs = np.linspace(51, 99, 100)
colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))


posterior_predictive_likelihood = posterior_predictive_base.posterior_predictive[
    &quot;likelihood&quot;
].stack(sample=(&quot;chain&quot;, &quot;draw&quot;))

posterior_predictive_likelihood_inv = endog_scaler.inverse_transform(
    X=posterior_predictive_likelihood.to_numpy()
)

fig, ax = plt.subplots(figsize=(12, 6))

for i, p in enumerate(percs[::-1]):
    upper = np.percentile(posterior_predictive_likelihood_inv, p, axis=1)
    lower = np.percentile(posterior_predictive_likelihood_inv, 100 - p, axis=1)
    color_val = colors[i]
    ax.fill_between(
        x=date,
        y1=upper,
        y2=lower,
        color=cmap(color_val),
        alpha=0.1,
    )

sns.lineplot(
    x=date,
    y=posterior_predictive_likelihood_inv.mean(axis=1),
    color=&quot;C2&quot;,
    label=&quot;posterior predictive mean&quot;,
    ax=ax,
)
sns.lineplot(
    x=date,
    y=cnt,
    color=&quot;black&quot;,
    label=target,
    ax=ax,
)
ax.legend(loc=&quot;upper left&quot;)
ax.set(
    title=&quot;Base Model - Posterior Predictive Samples&quot;,
    xlabel=&quot;date&quot;,
    ylabel=target,
)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_31_1.png" style="width: 1000px;"/>
</center>
<p>Observe that for certain points in July the predictions and the fit do not coincide and go in opposite directions. This will be solved by adding the time-varying coefficient to the linear model for the temperature regressor (see below).</p>
<p><strong>Remark</strong>: Note that the model predict negative values for the bike rentals. This is of course not good! An alterative choice of likelihood to model count data would resolve this (e.g.Â Poisson or Negative Binomial likelihoods).</p>
</div>
</div>
<div id="time-varying-coefficients-model" class="section level2">
<h2>Time-Varying Coefficients Model</h2>
<p>We now follow the same workflow above. The main difference is that we replace the regression coefficient of the temperature with <a href="https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.GaussianRandomWalk.html">GaussianRandomWalk</a> and remove the intercept term.</p>
<div id="model-specification-1" class="section level3">
<h3>1. Model Specification</h3>
<pre class="python"><code>with pm.Model(coords=coords) as model:
    # --- priors ---
    b_hum = pm.Normal(name=&quot;b_hum&quot;, mu=0, sigma=1)
    b_windspeed = pm.Normal(name=&quot;b_windspeed&quot;, mu=0, sigma=1)
    b_holiday = pm.ZeroSumNormal(name=&quot;b_holiday&quot;, sigma=1, dims=&quot;holiday&quot;)
    b_workingday = pm.ZeroSumNormal(name=&quot;b_workingday&quot;, sigma=1, dims=&quot;workingday&quot;)
    b_weathersit = pm.ZeroSumNormal(name=&quot;b_weathersit&quot;, sigma=1, dims=&quot;weathersit&quot;)
    b_t = pm.Normal(name=&quot;b_t&quot;, mu=0, sigma=2)
    b_eoy = pm.Normal(name=&quot;b_eoy&quot;, mu=0, sigma=1)
    sigma_slopes = pm.Exponential(name=&quot;sigma_slope&quot;, lam=1 / 0.2)
    nu = pm.Gamma(name=&quot;nu&quot;, alpha=8, beta=2)
    sigma = pm.HalfNormal(name=&quot;sigma&quot;, sigma=1)

    # --- model parametrization ---
    slopes = pm.GaussianRandomWalk(
        name=&quot;slopes&quot;,
        sigma=sigma_slopes,
        init_dist=Exponential.dist(lam=1 / 0.1),
        dims=&quot;date&quot;,
    )
    mu = pm.Deterministic(
        name=&quot;mu&quot;,
        var=(
            b_t * t
            + slopes * temp_scaled
            + b_hum * hum_scaled
            + b_windspeed * windspeed_scaled
            + b_holiday[holiday_idx]
            + b_workingday[workingday_idx]
            + b_weathersit[weathersit_idx]
            + b_eoy * eoy
        ),
        dims=&quot;date&quot;,
    )

    # --- likelihood ---
    likelihood = pm.StudentT(
        name=&quot;likelihood&quot;, mu=mu, nu=nu, sigma=sigma, dims=&quot;date&quot;, observed=cnt_scaled
    )


pm.model_to_graphviz(model)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_35_0.svg" style="width: 1000px;"/>
</center>
</div>
<div id="prior-predictive-analysis-1" class="section level3">
<h3>2. Prior Predictive Analysis</h3>
<pre class="python"><code>with model:
    # --- prior samples ---
    prior_predictive = pm.sample_prior_predictive(samples=200, random_seed=rng)


palette = &quot;viridis_r&quot;
cmap = plt.get_cmap(palette)
percs = np.linspace(51, 99, 100)
colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))


fig, ax = plt.subplots(figsize=(12, 6))

for i, p in enumerate(percs[::-1]):
    upper = np.percentile(prior_predictive.prior_predictive[&quot;likelihood&quot;], p, axis=1)
    lower = np.percentile(
        prior_predictive.prior_predictive[&quot;likelihood&quot;], 100 - p, axis=1
    )
    color_val = colors[i]
    ax.fill_between(
        x=date,
        y1=upper.flatten(),
        y2=lower.flatten(),
        color=cmap(color_val),
        alpha=0.1,
    )
sns.lineplot(x=date, y=cnt_scaled, color=&quot;black&quot;, ax=ax)
ax.set(
    title=&quot;Time-Varying Coefficient Model - Prior Predictive Samples&quot;,
    xlabel=&quot;date&quot;,
    ylabel=target_scaled,
)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_37_2.png" style="width: 1000px;"/>
</center>
</div>
<div id="model-fit-1" class="section level3">
<h3>3. Model Fit</h3>
<pre class="python"><code>with model:
    idata = pm.sample(
        target_accept=0.97,
        draws=2_000,
        chains=5,
        nuts_sampler=&quot;numpyro&quot;,
        idata_kwargs={&quot;log_likelihood&quot;: True},
        random_seed=rng,
    )
    posterior_predictive = pm.sample_posterior_predictive(
        trace=idata, random_seed=rng
    )</code></pre>
<pre class="python"><code># get number of divergences
idata[&quot;sample_stats&quot;][&quot;diverging&quot;].sum().item()
</code></pre>
<pre><code>13</code></pre>
<p>We get a small number of divergences ðŸ˜” â€¦ still not dramatic.</p>
</div>
<div id="model-diagnostics-1" class="section level3">
<h3>4. Model Diagnostics</h3>
<pre class="python"><code>az.summary(data=idata, var_names=[&quot;~mu&quot;, &quot;~slopes&quot;])</code></pre>
<center>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
mean
</th>
<th>
sd
</th>
<th>
hdi_3%
</th>
<th>
hdi_97%
</th>
<th>
mcse_mean
</th>
<th>
mcse_sd
</th>
<th>
ess_bulk
</th>
<th>
ess_tail
</th>
<th>
r_hat
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
b_hum
</th>
<td>
-0.077
</td>
<td>
0.019
</td>
<td>
-0.112
</td>
<td>
-0.040
</td>
<td>
0.001
</td>
<td>
0.001
</td>
<td>
656.0
</td>
<td>
2021.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_windspeed
</th>
<td>
-0.082
</td>
<td>
0.016
</td>
<td>
-0.111
</td>
<td>
-0.052
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
2182.0
</td>
<td>
5512.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_t
</th>
<td>
0.399
</td>
<td>
0.033
</td>
<td>
0.336
</td>
<td>
0.459
</td>
<td>
0.004
</td>
<td>
0.003
</td>
<td>
87.0
</td>
<td>
424.0
</td>
<td>
1.06
</td>
</tr>
<tr>
<th>
b_eoy
</th>
<td>
-0.248
</td>
<td>
0.037
</td>
<td>
-0.316
</td>
<td>
-0.175
</td>
<td>
0.001
</td>
<td>
0.001
</td>
<td>
1852.0
</td>
<td>
3498.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_holiday[HOLIDAY]
</th>
<td>
-0.043
</td>
<td>
0.008
</td>
<td>
-0.057
</td>
<td>
-0.027
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
2628.0
</td>
<td>
6585.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_holiday[NO HOLIDAY]
</th>
<td>
0.043
</td>
<td>
0.008
</td>
<td>
0.027
</td>
<td>
0.057
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
2628.0
</td>
<td>
6585.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_workingday[NO WORKING DAY]
</th>
<td>
-0.005
</td>
<td>
0.003
</td>
<td>
-0.010
</td>
<td>
-0.000
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
12229.0
</td>
<td>
9441.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_workingday[WORKING DAY]
</th>
<td>
0.005
</td>
<td>
0.003
</td>
<td>
0.000
</td>
<td>
0.010
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
12229.0
</td>
<td>
9441.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_weathersit[GOOD]
</th>
<td>
0.102
</td>
<td>
0.006
</td>
<td>
0.090
</td>
<td>
0.113
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
2059.0
</td>
<td>
5124.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_weathersit[MISTY]
</th>
<td>
0.049
</td>
<td>
0.007
</td>
<td>
0.037
</td>
<td>
0.062
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
5743.0
</td>
<td>
7402.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
b_weathersit[RAIN/SNOW/STORM]
</th>
<td>
-0.151
</td>
<td>
0.011
</td>
<td>
-0.172
</td>
<td>
-0.129
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
2845.0
</td>
<td>
5447.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
sigma_slope
</th>
<td>
0.044
</td>
<td>
0.006
</td>
<td>
0.033
</td>
<td>
0.055
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
212.0
</td>
<td>
347.0
</td>
<td>
1.02
</td>
</tr>
<tr>
<th>
nu
</th>
<td>
2.564
</td>
<td>
0.349
</td>
<td>
1.925
</td>
<td>
3.204
</td>
<td>
0.006
</td>
<td>
0.004
</td>
<td>
3667.0
</td>
<td>
7415.0
</td>
<td>
1.00
</td>
</tr>
<tr>
<th>
sigma
</th>
<td>
0.042
</td>
<td>
0.003
</td>
<td>
0.035
</td>
<td>
0.048
</td>
<td>
0.000
</td>
<td>
0.000
</td>
<td>
811.0
</td>
<td>
2206.0
</td>
<td>
1.01
</td>
</tr>
</tbody>
</table>
</div>
</center>
<pre class="python"><code>axes = az.plot_trace(
    data=idata,
    var_names=[&quot;~mu&quot;, &quot;~slopes&quot;],
    compact=True,
    kind=&quot;rank_bars&quot;,
    backend_kwargs={&quot;figsize&quot;: (12, 15), &quot;layout&quot;: &quot;constrained&quot;},
)
plt.gcf().suptitle(&quot;Time-Varying Coefficient Model - Trace&quot;, fontsize=16)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_44_1.png" style="width: 1000px;"/>
</center>
<p>Let us now compare the two models in a forest plot.</p>
<pre class="python"><code>axes = az.plot_forest(
    data=[idata_base, idata],
    model_names=[&quot;base&quot;, &quot;time-varying&quot;],
    var_names=[&quot;~mu&quot;, &quot;~slopes&quot;, &quot;~nu&quot;, &quot;~sigma&quot;],
    combined=True,
    r_hat=True,
    ess=True,
    figsize=(12, 7),
)
axes[0].axvline(x=0.0, color=&quot;black&quot;, linestyle=&quot;--&quot;)
plt.gcf().suptitle(&quot;Posterior Distributions&quot;, fontsize=16)
</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_46_1.png" style="width: 1000px;"/>
</center>
<p>Overall, there is no major change in the estimated regression coefficients besides the trend component.</p>
<p>We can also use the <a href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_compare.html"><code>az.compare</code></a> method to compare the two models.</p>
<pre class="python"><code>az.compare(compare_dict={&quot;base&quot;: idata_base, &quot;time-varying&quot;: idata})
</code></pre>
<center>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
rank
</th>
<th>
elpd_loo
</th>
<th>
p_loo
</th>
<th>
elpd_diff
</th>
<th>
weight
</th>
<th>
se
</th>
<th>
dse
</th>
<th>
warning
</th>
<th>
scale
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
time-varying
</th>
<td>
0
</td>
<td>
859.510979
</td>
<td>
190.554494
</td>
<td>
0.000000
</td>
<td>
0.924529
</td>
<td>
28.507826
</td>
<td>
0.000000
</td>
<td>
False
</td>
<td>
log
</td>
</tr>
<tr>
<th>
base
</th>
<td>
1
</td>
<td>
668.611994
</td>
<td>
11.713275
</td>
<td>
190.898985
</td>
<td>
0.075471
</td>
<td>
24.952297
</td>
<td>
21.054906
</td>
<td>
False
</td>
<td>
log
</td>
</tr>
</tbody>
</table>
</div>
<center>
<p>It seems that the time-varying coefficient model is better at predicting the bike rentals.</p>
</div>
<div id="posterior-predictive-distribution-1" class="section level3">
<h3>5. Posterior Predictive Distribution</h3>
<pre class="python"><code>palette = &quot;viridis_r&quot;
cmap = plt.get_cmap(palette)
percs = np.linspace(51, 99, 100)
colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))


posterior_predictive_likelihood = posterior_predictive.posterior_predictive[
    &quot;likelihood&quot;
].stack(sample=(&quot;chain&quot;, &quot;draw&quot;))

posterior_predictive_likelihood_inv = endog_scaler.inverse_transform(
    X=posterior_predictive_likelihood.to_numpy()
)

fig, ax = plt.subplots(figsize=(12, 6))

for i, p in enumerate(percs[::-1]):
    upper = np.percentile(posterior_predictive_likelihood_inv, p, axis=1)
    lower = np.percentile(posterior_predictive_likelihood_inv, 100 - p, axis=1)
    color_val = colors[i]
    ax.fill_between(
        x=date,
        y1=upper,
        y2=lower,
        color=cmap(color_val),
        alpha=0.1,
    )

sns.lineplot(
    x=date,
    y=posterior_predictive_likelihood_inv.mean(axis=1),
    color=&quot;C2&quot;,
    label=&quot;posterior predictive mean&quot;,
    ax=ax,
)
sns.lineplot(
    x=date,
    y=cnt,
    color=&quot;black&quot;,
    label=target,
    ax=ax,
)
ax.legend(loc=&quot;upper left&quot;)
ax.set(
    title=&quot;Time-Varying Coefficient Model - Posterior Predictive Samples&quot;,
    xlabel=&quot;date&quot;,
    ylabel=target,
)
</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_52_1.png" style="width: 1000px;"/>
</center>
</div>
<div id="temperature-effect-deep-dive" class="section level3">
<h3>6. Temperature Effect Deep-Dive</h3>
<p>Next, we wan to compare the inferred temperature effect from both models. To begin with, let us compare the mean effect for both models.</p>
<pre class="python"><code>base_tmp_mean = (
    idata_base.posterior[&quot;b_temp&quot;].stack(sample=(&quot;chain&quot;, &quot;draw&quot;)).to_numpy().mean()
)
time_varying_tmp_mean = (
    idata.posterior[&quot;slopes&quot;].stack(sample=(&quot;chain&quot;, &quot;draw&quot;)).to_numpy().mean()
)
print(
    f&quot;&quot;&quot;
base model mean effect = {base_tmp_mean: 0.3f}
------------------------------------------
time-varying model mean effect  = {time_varying_tmp_mean: 0.3f}
------------------------------------------
&quot;&quot;&quot;
)</code></pre>
<pre><code>base model mean effect =  0.473
------------------------------------------
time-varying model mean effect  =  0.536
------------------------------------------</code></pre>
<p>It seems that the effect of the time-varying coefficient model is higher. Still, this is just one statistic.It is always better to see the data. The following plot shows the effect as a function of the temperature.</p>
<pre class="python"><code>fig, ax = plt.subplots(figsize=(12, 7))
sns.scatterplot(
    x=&quot;temp&quot;,
    y=&quot;slopes&quot;,
    data=data_df.assign(slopes=idata.posterior[&quot;slopes&quot;].mean(dim=[&quot;chain&quot;, &quot;draw&quot;])),
    hue=&quot;mnth&quot;,
    palette=&quot;tab20&quot;,
)
sns.lineplot(
    x=&quot;temp&quot;,
    y=&quot;b_temp&quot;,
    data=data_df.assign(
        b_temp=idata_base.posterior[&quot;b_temp&quot;].mean(dim=[&quot;chain&quot;, &quot;draw&quot;]).to_numpy()
    ),
    color=&quot;black&quot;,
    label=&quot;base model&quot;,
    ax=ax,
)
sns.rugplot(x=data_df[&quot;temp&quot;], color=&quot;black&quot;, alpha=0.5, ax=ax)
ax.axhline(y=0.0, color=&quot;gray&quot;, linestyle=&quot;--&quot;)
ax.legend(loc=&quot;center left&quot;, bbox_to_anchor=(1, 0.5))
ax.set(title=&quot;Temperature Effect&quot;, xlabel=&quot;temp&quot;, ylabel=&quot;effect&quot;)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_56_1.png" style="width: 1000px;"/>
</center>
<p>We see many interesting features from this plot:</p>
<ul>
<li>The time-varying coefficient model indeed finds a non constant effect of temperature on bike rentals.</li>
<li>The effect of second model is always positive and starts decreasing at around <span class="math inline">\(15\)</span> degrees which is consistent with the results found in the previous post <a href="https://juanitorduz.github.io/interpretable_ml/">Exploring Tools for Interpretable Machine Learning</a>.</li>
<li>The lowest points of the effect are:
<ul>
<li>December and January. I think this is some seasonality effect that is not captured by the model.</li>
<li>During the summer months when the temperatures are very high, the effect decreases considerably.</li>
</ul></li>
<li>The variance of the time-varying effect decreases with the temperature.</li>
</ul>
<p>Next, we plot the temperature effect as a function of time.</p>
<pre class="python"><code>palette = &quot;cividis_r&quot;
cmap = plt.get_cmap(palette)
percs = np.linspace(51, 99, 100)
colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))


posterior_predictive_slopes = idata.posterior[&quot;slopes&quot;].stack(sample=(&quot;chain&quot;, &quot;draw&quot;))

fig, ax = plt.subplots(
    nrows=2, ncols=1, figsize=(10, 6), sharex=True, sharey=False, layout=&quot;constrained&quot;
)

for i, p in enumerate(percs[::-1]):
    upper = np.percentile(posterior_predictive_slopes, p, axis=1)
    lower = np.percentile(posterior_predictive_slopes, 100 - p, axis=1)
    color_val = colors[i]
    ax[0].fill_between(
        x=date,
        y1=upper,
        y2=lower,
        color=cmap(color_val),
        alpha=0.1,
    )

sns.lineplot(
    x=&quot;date&quot;,
    y=&quot;b_temp&quot;,
    data=data_df.assign(
        b_temp=idata_base.posterior[&quot;b_temp&quot;]
        .stack(sample=(&quot;chain&quot;, &quot;draw&quot;))
        .mean()
        .to_numpy()
    ),
    color=&quot;black&quot;,
    label=&quot;base model&quot;,
    ax=ax[0],
)
ax[0].axhline(y=0.0, color=&quot;gray&quot;, linestyle=&quot;--&quot;)
ax[0].legend(loc=&quot;upper left&quot;)
ax[0].set(title=&quot;Temperature Effect&quot;)
sns.lineplot(x=&quot;date&quot;, y=&quot;temp&quot;, data=data_df, color=&quot;C0&quot;, ax=ax[1])
ax[1].set(title=&quot;Temperature&quot;)</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_58_1.png" style="width: 1000px;"/>
</center>
<p>In the time-varying coefficient model, the temperature effect oscillates around the constant effect of the baseline model. We do see that during the spring months the effect is higher than the constant effect of the baseline model. This is consistent with the previous plot.</p>
<p>We can transform the scale back into the original scale:</p>
<pre class="python"><code>temp_effect_scaled_baseline = (
    idata_base[&quot;posterior&quot;][&quot;b_temp&quot;] * exog_scaler.scale_[0]
) / endog_scaler.scale_[0]

temp_effect_scaled = (
    idata[&quot;posterior&quot;][&quot;slopes&quot;] * exog_scaler.scale_[0]
) / endog_scaler.scale_[0]

fig, ax = plt.subplots(figsize=(12, 7))
az.plot_hdi(
    x=data_df[&quot;temp&quot;].to_numpy(),
    y=temp_effect_scaled,
    hdi_prob=0.94,
    color=&quot;C0&quot;,
    fill_kwargs={&quot;alpha&quot;: 0.4, &quot;label&quot;: &quot;$94\%$ HDI&quot;},
    ax=ax,
)
az.plot_hdi(
    x=data_df[&quot;temp&quot;].to_numpy(),
    y=temp_effect_scaled,
    hdi_prob=0.5,
    color=&quot;C0&quot;,
    fill_kwargs={&quot;alpha&quot;: 0.6, &quot;label&quot;: &quot;$50\%$ HDI&quot;},
    ax=ax,
)
ax.axhline(
    y=temp_effect_scaled_baseline.mean(dim=[&quot;chain&quot;, &quot;draw&quot;]).item(),
    color=&quot;C1&quot;,
    linestyle=&quot;--&quot;,
    label=&quot;base model posterior predictive mean&quot;,
)
sns.rugplot(x=data_df[&quot;temp&quot;], color=&quot;black&quot;, alpha=0.5, ax=ax)
ax.axhline(y=0.0, color=&quot;gray&quot;, linestyle=&quot;--&quot;)
ax.legend(loc=&quot;upper right&quot;)
ax.set(
    title=&quot;Temperature Coefficient (Original Scale) - Posterior Predictive&quot;,
    xlabel=&quot;temp&quot;,
    ylabel=None,
)
</code></pre>
<center>
<img src="../images/bikes_pymc_files/bikes_pymc_61_1.png" style="width: 1000px;"/>
</center>
<p>For temperatures lower than <span class="math inline">\(-2\)</span> the estimate is noisy and is probably leaking some seasonality effects.</p>
<p>Note that these results are compatible with the insights found on the previous post <a href="https://juanitorduz.github.io/interpretable_ml/">Exploring Tools for Interpretable Machine Learning</a>. For example, take a look into the PDP and ICE Pots</p>
<center>
<img src="../images/interpretable_ml_files/interpretable_ml_104_0.svg" style="width: 1000px;"/>
</center>
<p>and specifically here is are the same plots restricted to the month of July:</p>
<center>
<img src="../images/interpretable_ml_files/interpretable_ml_106_0.svg" style="width: 800px;"/>
</center>
<p>Here we see the negative effect of temperature on bike count for the summer months.</p>
<p><strong>Remark:</strong> It would be interesting to compare these results with <a href="https://orbit-ml.readthedocs.io/en/stable/tutorials/ktr1.html">Orbitâ€™s KTR model</a> (see <a href="https://juanitorduz.github.io/orbit_mmm/">Media Effect Estimation with Orbitâ€™s KTR Model</a>)</p>
</div>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/yaml.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/dockerfile.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'G-5NM5EDH834', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

