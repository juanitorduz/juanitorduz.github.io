<!DOCTYPE html>
<html lang="en-us">
  <head>
    <script defer src="https://use.fontawesome.com/releases/v5.13.0/js/all.js"></script>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.1" />


<title>PyConDE &amp; PyData Berlin 2022: Introduction to Uplift Modeling - Dr. Juan Camilo Orduz</title>
<meta property="og:title" content="PyConDE &amp; PyData Berlin 2022: Introduction to Uplift Modeling - Dr. Juan Camilo Orduz">


  <link href='../images/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/sphere2.gif"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../about/"> About</a></li>
    
    <li><a href="https://github.com/juanitorduz"><i class='fab fa-github fa-2x'></i>  </a></li>
    
    <li><a href="https://www.linkedin.com/in/juanitorduz/"><i class='fab fa-linkedin fa-2x' style='color:#0077B5;'></i>  </a></li>
    
    <li><a href="https://twitter.com/juanitorduz"><i class='fab fa-twitter fa-2x' style='color:#1DA1F2;'></i>  </a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">19 min read</span>
    

    <h1 class="article-title">PyConDE &amp; PyData Berlin 2022: Introduction to Uplift Modeling</h1>

    
    <span class="article-date">2022-04-11</span>
    

    <div class="article-content">
      
<script src="../rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>In this notebook we present a simple example of <a href="https://en.wikipedia.org/wiki/Uplift_modelling">uplift modeling</a> estimation via <em>meta-models</em> using <a href="https://github.com/uber/causalml"><code>causalml</code></a> and <a href="scikit-uplift"><code>scikit-uplift</code></a>. For a more detailed introduction to uplift modeling, see:</p>
<ul>
<li><p><a href="http://ama.imag.fr/~amini/Publis/large-scale-benchmark.pdf">Diemert, Eustache, et.al. (2020) <em>“A Large Scale Benchmark for Uplift Modeling”</em></a></p></li>
<li><p><a href="https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf">Gutierrez, P., &amp; Gérardy, J. Y. (2017). <em>“Causal Inference and Uplift Modelling: A Review of the Literature”</em></a></p></li>
<li><p><a href="http://www.diva-portal.org/smash/get/diva2:1328437/FULLTEXT01.pdf">Karlsson, H. (2019) <em>“Uplift Modeling: Identifying Optimal Treatment Group Allocation and Whom to Contact to Maximize Return on Investment”</em></a></p></li>
<li><p><a href="https://arxiv.org/abs/1706.03461">Sören, R, et.al. (2019) <em>“Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning”</em></a></p></li>
<li><p><a href="https://www.uplift-modeling.com/en/latest/user_guide/index.html"><code>scikit-uplift</code>’s User Guide</a></p></li>
</ul>
<p>This material was presented at <a href="https://2022.pycon.de/">PyCon DE &amp; PyData Berlin2022</a>: <a href="https://2022.pycon.de/program/QY7P98/">Introduction to Uplift Modeling</a>.</p>
<p>Here you can find the recording of the talk:</p>
<center>
<iframe width="600" height="400" src="https://www.youtube.com/embed/VWjsi-5yc3w?rel=0" frameborder="0" allowfullscreen>
</iframe>
</center>
<p><a href="../Presentations/pydata_2022/intro_uplift.pdf">Here</a> you can find the slides.</p>
<iframe src="../html/intro_uplift.html" width="90%" height="500px">
</iframe>
<hr />
<div id="prepare-notebook" class="section level2">
<h2>Prepare Notebook</h2>
<pre class="python"><code>from causalml.inference.meta.base import BaseLearner
from causalml.inference.meta import(
    BaseSClassifier,
    BaseTClassifier,
    BaseXClassifier,
)
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.ensemble import (
    HistGradientBoostingClassifier,
    HistGradientBoostingRegressor,
)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklift.metrics import uplift_by_percentile, uplift_curve
from sklift.viz import (
    plot_qini_curve,
    plot_uplift_by_percentile,
    plot_uplift_curve,
)
plt.style.use(&quot;bmh&quot;)
plt.rcParams[&quot;figure.figsize&quot;] = [10, 6]
plt.rcParams[&quot;figure.dpi&quot;] = 100
%load_ext autoreload
%autoreload 2
%config InlineBackend.figure_format = &quot;svg&quot;</code></pre>
</div>
<div id="read-data" class="section level2">
<h2>Read Data</h2>
<p>We are going to follow the example <a href="https://www.uplift-modeling.com/en/latest/tutorials.html#id1">The overview of the basic approaches to solving the Uplift Modeling problem</a> presented in <a href="https://www.uplift-modeling.com/en/latest/user_guide/index.html"><code>scikit-uplift</code>’s Tutorials Section</a>. We extend such example by adding and EDA section on the data and using <a href="https://github.com/uber/causalml"><code>causalml</code></a> for the uplift estimation. We do use the <code>sklift.viz</code> to get diagnostics plots.</p>
<p>Data set: <a href="https://ods.ai/competitions/x5-retailhero-uplift-modeling/data">RetailHero.ai contest data</a></p>
<pre class="python"><code>from pathlib import Path

data_path = Path(&quot;~/data&quot;)

# clients data
clients_df = pd.read_csv(
    data_path / &quot;clients.csv&quot;, parse_dates=[&quot;first_issue_date&quot;, &quot;first_redeem_date&quot;]
)
# treatment and target data
uplift_train_df = pd.read_csv(data_path / &quot;uplift_train.csv&quot;)
</code></pre>
<ul>
<li><code>clients_df</code> data:</li>
</ul>
<pre class="python"><code>clients_df.info()
</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 400162 entries, 0 to 400161
Data columns (total 5 columns):
 #   Column             Non-Null Count   Dtype         
---  ------             --------------   -----         
 0   client_id          400162 non-null  object        
 1   first_issue_date   400162 non-null  datetime64[ns]
 2   first_redeem_date  364693 non-null  datetime64[ns]
 3   age                400162 non-null  int64         
 4   gender             400162 non-null  object        
dtypes: datetime64[ns](2), int64(1), object(2)
memory usage: 15.3+ MB</code></pre>
<ul>
<li><code>uplift_train_df</code> data:</li>
</ul>
<pre class="python"><code>uplift_train_df.info()
</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 200039 entries, 0 to 200038
Data columns (total 3 columns):
 #   Column         Non-Null Count   Dtype 
---  ------         --------------   ----- 
 0   client_id      200039 non-null  object
 1   treatment_flg  200039 non-null  int64 
 2   target         200039 non-null  int64 
dtypes: int64(2), object(1)
memory usage: 4.6+ MB</code></pre>
<ul>
<li><code>purchases_df</code> data:</li>
</ul>
<pre class="python"><code>purchases_df = pd.read_csv(data_path / &quot;purchases.csv&quot;)

purchases_df.info()
</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 45786568 entries, 0 to 45786567
Data columns (total 13 columns):
 #   Column                   Dtype  
---  ------                   -----  
 0   client_id                object 
 1   transaction_id           object 
 2   transaction_datetime     object 
 3   regular_points_received  float64
 4   express_points_received  float64
 5   regular_points_spent     float64
 6   express_points_spent     float64
 7   purchase_sum             float64
 8   store_id                 object 
 9   product_id               object 
 10  product_quantity         float64
 11  trn_sum_from_iss         float64
 12  trn_sum_from_red         float64
dtypes: float64(8), object(5)
memory usage: 4.4+ GB</code></pre>
</div>
<div id="eda" class="section level2">
<h2>EDA</h2>
<p>Let us start by exploring the data. First, let us take a look into the target and treatment variables:</p>
<pre class="python"><code>fig, ax = plt.subplots()

uplift_train_df \
  .groupby([&quot;treatment_flg&quot;, &quot;target&quot;], as_index=False) \
  .size() \
  .assign(
    share=lambda x: x[&quot;size&quot;] / x[&quot;size&quot;].sum()
  ) \
  .pipe((sns.barplot, &quot;data&quot;), x=&quot;target&quot;, y=&quot;share&quot;, hue=&quot;treatment_flg&quot;, ax=ax)
ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: f&quot;{y :.0%}&quot;))
ax.set(title=&quot;Targer by treatment distribution&quot;);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_12_1.svg" alt="html" style="width: 800px;"/>
</center>
<p>We have approximately 50/50 split of the <code>treatment_flg</code> but the <code>target</code> is not balanced (approx. 40/60).</p>
<p>Now we examine the clients data. First we count the unique number of <code>client_id</code>.</p>
<pre class="python"><code>assert clients_df.shape[0] == clients_df[&quot;client_id&quot;].nunique()
assert uplift_train_df.shape[0] == uplift_train_df[&quot;client_id&quot;].nunique()

print(f&quot;&quot;&quot;
clients_id
----------
clients_df: {clients_df[&quot;client_id&quot;].nunique()}
uplift_train_df: {uplift_train_df[&quot;client_id&quot;].nunique()}
&quot;&quot;&quot;)
</code></pre>
<pre><code>clients_id
----------
clients_df: 400162
uplift_train_df: 200039</code></pre>
<p>We have more <code>client_id</code> in the <code>clients_df</code>. Next we merge the data by <code>client_id</code>.</p>
<pre class="python"><code>raw_data_df = pd.merge(
    left=clients_df, right=uplift_train_df, on=&quot;client_id&quot;, how=&quot;outer&quot;
)

assert raw_data_df.shape[0] == clients_df.shape[0]
assert raw_data_df.shape[0] == raw_data_df[&quot;client_id&quot;].nunique()
</code></pre>
<p>We continue by taking a look into the <code>gender</code> feature.</p>
<p><strong>Warning:</strong> Including <code>gender</code>-like variables in ML models can induce undesirable biases. We do keep this feature just because we want to compare the techniques with the original example.</p>
<pre class="python"><code>g = (
    raw_data_df.query(&quot;target.notnull()&quot;)
    .groupby([&quot;treatment_flg&quot;, &quot;target&quot;, &quot;gender&quot;], as_index=False)
    .agg(count=(&quot;client_id&quot;, &quot;count&quot;))
    .pipe(
        (sns.catplot, &quot;data&quot;),
        x=&quot;target&quot;,
        y=&quot;count&quot;,
        hue=&quot;gender&quot;,
        col=&quot;treatment_flg&quot;,
        kind=&quot;bar&quot;,
    )
)
</code></pre>
<center>
<img src="../images/uplift_files/uplift_19_0.svg" alt="html" style="width: 800px;"/>
</center>
<p>Now we plot the <code>age distribution</code>. Note however, we need to remove some outliers:</p>
<pre class="python"><code># reasonable age range
good_age_mask = &quot;10 &lt; age &lt; 100&quot;

print( f&quot;&quot;&quot;
Rows with age outliers: 
{1 - clients_df.query(good_age_mask).shape[0] / clients_df.shape[0]: 0.2%}
&quot;&quot;&quot;)
</code></pre>
<pre><code>Rows with age outliers: 
 0.37%</code></pre>
<pre class="python"><code>raw_data_df.query(&quot;(target.notnull()) and (10 &lt; age &lt; 100)&quot;).pipe(
    (sns.displot, &quot;data&quot;), x=&quot;age&quot;, hue=&quot;gender&quot;, col=&quot;treatment_flg&quot;, kind=&quot;kde&quot;
);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_22_1.svg" alt="html" style="width: 800px;"/>
</center>
<p>We continue by studying the time variables. Note that the variable <code>first_redeem_date</code> has missing values. Let us see target and treatment distribution over these missing values.</p>
<pre class="python"><code>g = (
    raw_data_df.assign(
        first_redeem_date_is_null=lambda x: x[&quot;first_redeem_date&quot;].isna()
    )
    .groupby(
      [&quot;treatment_flg&quot;, &quot;target&quot;, &quot;first_redeem_date_is_null&quot;], as_index=False
    )
    .agg(count=(&quot;client_id&quot;, &quot;count&quot;))
    .pipe(
        (sns.catplot, &quot;data&quot;),
        x=&quot;target&quot;,
        y=&quot;count&quot;,
        hue=&quot;first_redeem_date_is_null&quot;,
        col=&quot;treatment_flg&quot;,
        kind=&quot;bar&quot;,
    )
)
</code></pre>
<center>
<img src="../images/uplift_files/uplift_19_0.svg" alt="html" style="width: 800px;"/>
</center>
<p>We do not see any pattern at first glance. Let us see the development the client counts over <code>first_issue_date</code>.</p>
<pre class="python"><code>fig, ax = plt.subplots()

raw_data_df \
  .assign(first_issue_date=lambda x: x[&quot;first_issue_date&quot;].dt.date) \
  .groupby(
    [&quot;first_issue_date&quot;], as_index=False
  ) \
  .agg(count=(&quot;client_id&quot;, &quot;count&quot;)) \
  .pipe(
    (sns.lineplot, &quot;data&quot;),
    x=&quot;first_issue_date&quot;,
    y=&quot;count&quot;,
    label=&quot;first_issue_date&quot;,
    ax=ax,
)

raw_data_df \
  .query(&quot;first_redeem_date.isnull()&quot;) \
  .assign(
    first_issue_date=lambda x: x[&quot;first_issue_date&quot;].dt.date
  ) \
  .groupby([&quot;first_issue_date&quot;], as_index=False) \
  .agg(count=(&quot;client_id&quot;, &quot;count&quot;)) \
  .pipe(
    (sns.lineplot, &quot;data&quot;),
    x=&quot;first_issue_date&quot;,
    y=&quot;count&quot;,
    label=&quot;first_issue_date (first_redeem_date null)&quot;,
    ax=ax,
);</code></pre>
<center>
<img src="../images/uplift_files/uplift_26_1.svg" alt="html" style="width: 800px;"/>
</center>
<p>There seems to be missing values along the whole time period.</p>
<pre class="python"><code>print(f&quot;&quot;&quot;
rows share with missing values:
{raw_data_df.query(&quot;first_redeem_date.isnull()&quot;).shape[0] / raw_data_df.shape[0]: 0.2%}
&quot;&quot;&quot;)
</code></pre>
<pre><code>rows share with missing values:
 8.86%</code></pre>
<p>From this initial EDA there is no hint of the source of these missing values, i.e. they are at random (or maybe we are missing some information or context of the data?).</p>
<p>We now plot the client counts over <code>first_issue_date</code> and <code>first_redeem_date</code>:</p>
<pre class="python"><code>fig, ax = plt.subplots()

raw_data_df \
  .assign(first_issue_date=lambda x: x[&quot;first_issue_date&quot;].dt.date) \
  .groupby([&quot;first_issue_date&quot;], as_index=False) \
  .agg(count=(&quot;client_id&quot;, &quot;count&quot;)) \
  .pipe((sns.lineplot, &quot;data&quot;),
    x=&quot;first_issue_date&quot;,
    y=&quot;count&quot;,
    label=&quot;first_issue_date&quot;,
    ax=ax,
)

raw_data_df \
  .assign(first_redeem_date=lambda x: x[&quot;first_redeem_date&quot;].dt.date) \
  .groupby([&quot;first_redeem_date&quot;], as_index=False) \
  .agg(count=(&quot;client_id&quot;, &quot;count&quot;)) \
  .pipe((sns.lineplot, &quot;data&quot;),
    x=&quot;first_redeem_date&quot;,
    y=&quot;count&quot;,
    label=&quot;first_redeem_date&quot;,
    ax=ax,
)
ax.set(xlabel=&quot;date&quot;, ylabel=&quot;count&quot;)</code></pre>
<center>
<img src="../images/uplift_files/uplift_31_1.svg" alt="html" style="width: 800px;"/>
</center>
<p>Finally, in order to enrich our models, we calculate some simple summary metrics from the purchase data:</p>
<pre class="python"><code>client_purchases_summary_df = (
    purchases_df.groupby([&quot;client_id&quot;], as_index=False)
    .agg(
        n_transactions=(&quot;transaction_id&quot;, &quot;count&quot;),
        n_products=(&quot;product_id&quot;, &quot;nunique&quot;),
        n_stores=(&quot;store_id&quot;, &quot;nunique&quot;),
        last_transaction_date=(&quot;transaction_datetime&quot;, &quot;max&quot;),
        express_points_received=(&quot;express_points_received&quot;, np.sum),
        express_points_spent=(&quot;express_points_spent&quot;, np.sum),
        regular_points_spent=(&quot;regular_points_spent&quot;, np.sum),
        mean_product_quantity=(&quot;product_quantity&quot;, np.mean),
    )
    .assign(
      last_transaction_date=lambda x: pd.to_datetime(x[&quot;last_transaction_date&quot;])
    )
  )</code></pre>
<p><strong>Warning:</strong> We are using time-dependent features like <code>last_transaction_date = ("transaction_datetime", "max")</code>, which have to be treated carefully when doing out-of-sample validation. Below we will do a train-test split by randomly selecting a fraction of the data bases on the <code>client_id</code>. Nevertheless, to have a faithful out-of-sample evaluation metrics we might want to compute these features on each split otherwise we would be leaking information. For the sake of this toy-example we will not do this.</p>
</div>
<div id="prepare-data" class="section level2">
<h2>Prepare Data</h2>
<p>In this section we prepare the data for uplift modeling. We will use the features from the original example (with minor modifications) plus some purchase features.</p>
<pre class="python"><code># add purchase features
raw_data_ext_df = raw_data_df \
  .copy() \
  .merge(
    right=client_purchases_summary_df,
    on=&quot;client_id&quot;,
    how=&quot;left&quot;
)
</code></pre>
<pre class="python"><code>transformation_map = {
    &quot;first_issue_time&quot;: lambda x: (x[&quot;first_issue_date&quot;] - pd.Timestamp(&quot;2017-01-01&quot;)).dt.days,
    &quot;first_issue_time_weekday&quot;: lambda x: x[&quot;first_issue_date&quot;].dt.weekday,
    &quot;first_issue_time_month&quot;: lambda x: x[&quot;first_issue_date&quot;].dt.month,
    &quot;first_redeem_time&quot;: lambda x: (x[&quot;first_redeem_date&quot;] - pd.Timestamp(&quot;2017-01-01&quot;)).dt.days,
    &quot;issue_redeem_delay&quot;: lambda x: (x[&quot;first_redeem_time&quot;] - x[&quot;first_issue_time&quot;]),
    &quot;last_transaction_time&quot;: lambda x: (x[&quot;last_transaction_date&quot;] - pd.Timestamp(&quot;2017-01-01&quot;)).dt.days,
}

data_df = (
    raw_data_ext_df.copy()
    .query(&quot;target.notnull()&quot;)
    .query(good_age_mask)
    .set_index(&quot;client_id&quot;)
    .assign(**transformation_map)
    .sort_values(&quot;first_issue_time&quot;)
    .drop(
        columns=[
            &quot;first_issue_date&quot;,
            &quot;first_redeem_date&quot;,
            &quot;last_transaction_date&quot;,
        ]
    )
)

data_df.info()
</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 199305 entries, b5e94fd9dd to 903a531bb7
Data columns (total 17 columns):
 #   Column                    Non-Null Count   Dtype  
---  ------                    --------------   -----  
 0   age                       199305 non-null  int64  
 1   gender                    199305 non-null  object 
 2   treatment_flg             199305 non-null  float64
 3   target                    199305 non-null  float64
 4   n_transactions            199305 non-null  int64  
 5   n_products                199305 non-null  int64  
 6   n_stores                  199305 non-null  int64  
 7   express_points_received   199305 non-null  float64
 8   express_points_spent      199305 non-null  float64
 9   regular_points_spent      199305 non-null  float64
 10  mean_product_quantity     199305 non-null  float64
 11  first_issue_time          199305 non-null  int64  
 12  first_issue_time_weekday  199305 non-null  int64  
 13  first_issue_time_month    199305 non-null  int64  
 14  first_redeem_time         181873 non-null  float64
 15  issue_redeem_delay        181873 non-null  float64
 16  last_transaction_time     199305 non-null  int64  
dtypes: float64(8), int64(8), object(1)
memory usage: 27.4+ MB</code></pre>
<p>We can now show a pair-plot of the main features of the original example:</p>
<pre class="python"><code>sns.pairplot(
    data=data_df[
        [
            &quot;first_issue_time&quot;,
            &quot;first_redeem_time&quot;,
            &quot;issue_redeem_delay&quot;,
        ]
    ],
    kind=&quot;hist&quot;,
    height=2.5,
    aspect=1.5,
)
</code></pre>
<center>
<img src="../images/uplift_files/uplift_39_1.svg" alt="html" style="width: 900px;"/>
</center>
<p>Now we do a simple train-validation split of the data.</p>
<pre class="python"><code>target_col = &quot;target&quot;
treatment_col = &quot;treatment_flg&quot;

y = data_df[target_col]
w = data_df[treatment_col]
x = data_df.drop(columns=[treatment_col, target_col])

idx_train, idx_val = train_test_split(
    data_df.index,
    test_size=0.3,
    random_state=42,
    stratify=(y.astype(str) + &quot;_&quot; + w.astype(str)),
)

x_train = x.loc[idx_train]
x_val = x.loc[idx_val]

w_train = w.loc[idx_train]
w_val = w.loc[idx_val]

y_train = y.loc[idx_train]
y_val = y.loc[idx_val]
</code></pre>
<p>Let us encode the <code>gender</code> as an ordinal categorical variable.</p>
<pre class="python"><code>ordinal_encoder = OrdinalEncoder()
ordinal_encoder.fit(x_train[[&quot;gender&quot;]])

x_train_transformed = x_train.assign(
    gender=lambda x: ordinal_encoder.transform(x[[&quot;gender&quot;]])
)

x_val_transformed = x_val.assign(
    gender=lambda x: ordinal_encoder.transform(x[[&quot;gender&quot;]])
)
</code></pre>
</div>
<div id="propensity-score-model" class="section level2">
<h2>Propensity Score Model</h2>
<p>The propensity score are defined as <span class="math inline">\(p(X_{i}) = P(W_{i}=1 | X_{i})\)</span>, that is, the probability of having a treatment given the covariates. If the treatment assignment is at random these scores should be concentrated around 0.5. For a nice introduction to the subject you can see <a href="https://www.youtube.com/watch?v=gaUgW7NWai8">“Propensity Score Matching: A Non-experimental Approach to Causal Inference” by Michael Johns, PyData New York 2019</a>. We ser <code>scikit-learn</code>’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html"><code>HistGradientBoostingClassifier</code></a>. For this model we need to explicitly indicate the categorical variables:</p>
<pre class="python"><code>categorical_features = [&quot;gender&quot;]

hgc_params = {
    &quot;categorical_features&quot;: np.argwhere(
        [col in categorical_features for col in x_train_transformed.columns]
    ).flatten()
}
</code></pre>
<p>We now fit the model:</p>
<pre class="python"><code>propensity_model = HistGradientBoostingClassifier(**hgc_params)

propensity_model.fit(X=x_train_transformed, y=w_train)
p_train = propensity_model.predict_proba(X=x_train_transformed)
p_val = propensity_model.predict_proba(X=x_val_transformed)

p_train = pd.Series(p_train[:, 0], index=idx_train)
p_val = pd.Series(p_val[:, 0], index=idx_val)
</code></pre>
<p>Lets see the results:</p>
<pre class="python"><code>fig, ax = plt.subplots()
sns.kdeplot(x=p_train, label=&quot;train&quot;, ax=ax)
sns.kdeplot(x=p_val, label=&quot;val&quot;, ax=ax)
ax.legend()
ax.set(
    title=&quot;Propensity Score Predictions Distribution&quot;,
    xlabel=&quot;propensity score&quot;,
    ylabel=&quot;density&quot;,
);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_49_1.svg" alt="html" style="width: 800px;"/>
</center>
<pre class="python"><code>print(f&quot;&quot;&quot;
Share of predictions with |p - 0.5| &gt; 0.2 (train) {p_train[abs(p_train - 0.5) &gt; 0.2].size / p_train.size : 0.2%}
Share of predictions with |p - 0.5| &gt; 0.2 (val) {p_val[abs(p_val - 0.5) &gt; 0.2].size / p_val.size : 0.2%}
&quot;&quot;&quot;)
</code></pre>
<pre><code>Share of predictions with |p - 0.5| &gt; 0.2 (train)  1.46%
Share of predictions with |p - 0.5| &gt; 0.2 (val)  1.47%</code></pre>
<pre class="python"><code>from sklearn.inspection import permutation_importance

pi = permutation_importance(
    estimator=propensity_model, X=x_train_transformed, y=w_train
)

fig, ax = plt.subplots(figsize=(8, 8))

idx = pi[&quot;importances_mean&quot;].argsort()[::-1]

sns.barplot(
    x=pi[&quot;importances_mean&quot;][idx],
    y=x_train_transformed.columns[idx],
    color=&quot;C4&quot;,
    ax=ax
)
ax.set(title=&quot;Permutation importance propensity score model&quot;);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_51_1.svg" alt="html" style="width: 800px;"/>
</center>
</div>
<div id="data-container" class="section level2">
<h2>Data Container</h2>
<p>We now define a convenient data structure for the uplift models input data.</p>
<pre class="python"><code>from dataclasses import dataclass

@dataclass
class DataIn:
    x: pd.DataFrame
    x_transformed: np.array
    y: pd.Series
    treatment: pd.Series
    p: pd.Series


data_train = DataIn(
    x=x_train,
    x_transformed=x_train_transformed,
    y=y_train,
    treatment=w_train,
    p=p_train,
)

data_val = DataIn(
    x=x_val,
    x_transformed=x_val_transformed,
    y=y_val,
    treatment=w_val,
    p=p_val
)
</code></pre>
<hr />
</div>
<div id="models" class="section level2">
<h2>Models</h2>
<p>Now that we have a better understanding of the data we can start modeling. We use some of the <em>meta-learners</em> from <a href="https://github.com/uber/causalml"><code>causalml</code></a>. For more details please see the <a href="https://causalml.readthedocs.io/en/latest/methodology.html#meta-learner-algorithms"><code>causalml</code> documentation</a>.</p>
<div id="s-learner" class="section level3">
<h3>S-Learner</h3>
<p>In this meta-model we simply train an ML model to predict the <code>target</code> variable using the covariates <span class="math inline">\(X\)</span> plus the <code>target</code> as regressors.</p>
<ul>
<li><strong>Step 1: Training</strong></li>
</ul>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} &amp; w_{1} \\
\vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{nk} &amp; w_{n} \\
\end{array}
\right)}_{X\bigoplus W}
\xrightarrow{\mu}
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n}
\end{array}
\right)
\]</span></p>
<ul>
<li><strong>Step 2: Uplift Prediction</strong></li>
</ul>
<p><span class="math display">\[
\widehat{\text{uplift}} =
\hat{\mu}\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} &amp; 1 \\
\vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{mk} &amp; 1 \\
\end{array}
\right)
-
\hat{\mu}
\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{mk} &amp; 0 \\
\end{array}
\right)
\]</span></p>
<pre class="python"><code>s_learner = BaseSClassifier(learner=HistGradientBoostingClassifier(**hgc_params))

s_ate = s_learner.estimate_ate(
    X=data_train.x_transformed, treatment=data_train.treatment, y=data_train.y
)
</code></pre>
<p>One can access the trained model as:</p>
<pre class="python"><code>s_learner.models[1]
</code></pre>
<pre><code>HistGradientBoostingClassifier(categorical_features=array([1]))</code></pre>
</div>
<div id="t-learner" class="section level3">
<h3>T-Learner</h3>
<p>For this one we train two ML models instead: one for each treatment assignment.</p>
<ul>
<li><strong>Step 1: Training</strong></li>
</ul>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{ccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{C}k} \\
\end{array}
\right)}_{X|_{\text{control}}}
\xrightarrow{\mu_{C}}
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n_{C}}
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{ccc}
x_{11} &amp; \cdots &amp; x_{1k}  \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{T}k} \\
\end{array}
\right)}_{X |_{\text{treatment}}}
\xrightarrow{\mu_{T}}
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n_{T}}
\end{array}
\right)
\]</span></p>
<ul>
<li><strong>Step 2: Uplift Prediction</strong></li>
</ul>
<p><span class="math display">\[
\widehat{\text{uplift}} =
\hat{\mu}_{T}\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{mk} \\
\end{array}
\right)
-
\hat{\mu}_{C}
\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{mk} \\
\end{array}
\right)
\]</span></p>
<pre class="python"><code>t_learner = BaseTClassifier(learner=HistGradientBoostingClassifier(**hgc_params))

t_ate_lwr, t_ate, t_ate_upr = t_learner.estimate_ate(
    X=data_train.x_transformed, treatment=data_train.treatment, y=data_train.y
)
</code></pre>
<p>One can access the trained models as:</p>
<pre class="python"><code>t_learner.models_c[1]  # control group
t_learner.models_t[1]  # treatment group
</code></pre>
<pre><code>HistGradientBoostingClassifier(categorical_features=array([1]))</code></pre>
</div>
<div id="x-learner" class="section level3">
<h3>X-Learner</h3>
<p>The X-Learner is similar to the T-Learner but it adds and additional step where we transfer information from one model to the other, see <a href="https://arxiv.org/abs/1706.03461">Sören, R, et.al. (2019) <em>“Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning”</em></a> for details on the motivation.</p>
<ul>
<li><strong>Step 1: Training</strong></li>
</ul>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{ccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{C}k} \\
\end{array}
\right)}_{X|_{\text{control}}}
\xrightarrow{\mu_{C}}
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n_{C}}
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{ccc}
x_{11} &amp; \cdots &amp; x_{1k}  \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{T}k} \\
\end{array}
\right)}_{X |_{\text{treatment}}}
\xrightarrow{\mu_{T}}
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n_{T}}
\end{array}
\right)
\]</span></p>
<ul>
<li><strong>Step 2: Compute imputed treatment effects</strong></li>
</ul>
<p><span class="math display">\[
\tilde{D}^{T} :=
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n_{T}}
\end{array}
\right)
-
\hat{\mu}_{C}
\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{T}k} \\
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
\tilde{D}^{C} :=
\hat{\mu}_{T}
\left(
\begin{array}{cccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{C}k} \\
\end{array}
\right)
-
\left(
\begin{array}{c}
y_{1} \\
\vdots \\
y_{n_{C}}
\end{array}
\right)
\]</span></p>
<ul>
<li><strong>Step 3: Uplift train with different targets</strong></li>
</ul>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{ccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{C}k} \\
\end{array}
\right)}_{X|_{\text{control}}}
\xrightarrow{\tau_{C}}
\left(
\begin{array}{c}
\tilde{D}^{C}_{1} \\
\vdots \\
\tilde{D}^{C}_{n_{C}}
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
\underbrace{
\left(
\begin{array}{ccc}
x_{11} &amp; \cdots &amp; x_{1k} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{11} &amp; \cdots &amp; x_{n_{T}k} \\
\end{array}
\right)}_{X|_{\text{treatment}}}
\xrightarrow{\tau_{T}}
\left(
\begin{array}{c}
\tilde{D}^{T}_{1} \\
\vdots \\
\tilde{D}^{T}_{n_{T}}
\end{array}
\right)
\]</span></p>
<ul>
<li><strong>Step 4: Uplift Prediction</strong></li>
</ul>
<p><span class="math display">\[
\widehat{\text{uplift}} = g(x)\hat{\tau}_{C}(x) + (1 - g(x))\hat{\tau}_{T}(x)
\]</span></p>
<p>where <span class="math inline">\(g(x) \in [0, 1]\)</span> is a weight function.</p>
<p><strong>Remark:</strong> From <a href="https://arxiv.org/abs/1706.03461">Sören, R, et.al. (2019) <em>“Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning”</em></a>:</p>
<blockquote>
<p><em><span class="math inline">\(\hat{\tau}_{C}\)</span> and <span class="math inline">\(\hat{\tau}_{T}\)</span> are both estimators for <span class="math inline">\(\tau\)</span> (the uplift) while <span class="math inline">\(g\)</span> is chosen to combine these estimators to one improved estimator <span class="math inline">\(\hat{\tau}\)</span>. Based on our experience, we observe that it is good to use an estimate of the propensity score for <span class="math inline">\(g\)</span>, but it also makes sense to choose <span class="math inline">\(g = 1\)</span> or <span class="math inline">\(0\)</span>, if the number of treated units is very large or small compared to the number of control units.</em></p>
</blockquote>
<pre class="python"><code>x_learner = BaseXClassifier(
    outcome_learner=HistGradientBoostingClassifier(**hgc_params),
    effect_learner=HistGradientBoostingRegressor(**hgc_params),
)

x_ate_lwr, x_ate, x_ate_upr = x_learner.estimate_ate(
    X=data_train.x_transformed,
    treatment=data_train.treatment,
    y=data_train.y,
    p=data_train.p,
)
</code></pre>
<p>One can access the trained models as:</p>
<pre class="python"><code># step 1
x_learner.models_mu_c[1]  # control group
x_learner.models_mu_t[1]  # treatment group
# step 3
x_learner.models_tau_c[1]  # control group
x_learner.models_tau_t[1]  # treatment group
</code></pre>
<pre><code>HistGradientBoostingRegressor(categorical_features=array([1]))</code></pre>
<pre class="python"><code>fig, ax = plt.subplots(figsize=(6, 4))

pd.DataFrame(
    data={
        &quot;model&quot;: [&quot;s_learner&quot;, &quot;t_learner&quot;, &quot;x_learner&quot;],
        &quot;ate&quot;: np.array([s_ate, t_ate, x_ate]).flatten(),
    },
).pipe((sns.barplot, &quot;data&quot;), x=&quot;model&quot;, y=&quot;ate&quot;, ax=ax)
ax.set(title=&quot;ATE Estimation (Train)&quot;);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_67_1.svg" alt="html" style="width: 800px;"/>
</center>
<hr />
</div>
</div>
<div id="predictions-diagnostics" class="section level2">
<h2>Predictions &amp; Diagnostics</h2>
<p>Next, now that we have fitted meta-learner models, we generate predictions in the training and validations sets.</p>
<pre class="python"><code>@dataclass
class DataOut:
    meta_learner_name: str
    meta_learner: BaseLearner
    y_pred: np.array


# in-sample predictions
data_out_train_s = DataOut(
    meta_learner_name=&quot;S-Learner&quot;,
    meta_learner=s_learner,
    y_pred=s_learner.predict(
        X=data_train.x_transformed, treatment=data_train.treatment
    ),
)
data_out_train_t = DataOut(
    meta_learner_name=&quot;T-Learner&quot;,
    meta_learner=t_learner,
    y_pred=t_learner.predict(
        X=data_train.x_transformed, treatment=data_train.treatment
    ),
)
data_out_train_x = DataOut(
    meta_learner_name=&quot;X-Learner&quot;,
    meta_learner=x_learner,
    y_pred=x_learner.predict(
        X=data_train.x_transformed, treatment=data_train.treatment, p=data_train.p
    ),
)
# out-of-sample predictions
data_out_val_s = DataOut(
    meta_learner_name=&quot;S-Learner&quot;,
    meta_learner=s_learner,
    y_pred=s_learner.predict(
      X=data_val.x_transformed, treatment=data_val.treatment
    ),
)
data_out_val_t = DataOut(
    meta_learner_name=&quot;T-Learner&quot;,
    meta_learner=t_learner,
    y_pred=t_learner.predict(
      X=data_val.x_transformed, treatment=data_val.treatment
    ),
)
data_out_val_x = DataOut(
    meta_learner_name=&quot;X-Learner&quot;,
    meta_learner=x_learner,
    y_pred=x_learner.predict(
        X=data_val.x_transformed, treatment=data_val.treatment, p=data_val.p
    ),
)
</code></pre>
<p>A natural question is: how well do we predict the uplift? Note that (<a href="https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf">Gutierrez, P., &amp; Gérardy, J. Y. (2017). <em>“Causal Inference and Uplift Modelling: A Review of the Literature”</em></a>):</p>
<blockquote>
<p><em>In machine learning, the standard is to use cross-validation: separate the data into a training and a testing datasets; learn on the training data, predict the target on the test data and compare to the ground truth. In uplift modeling, cross validation is still a valid idea but there is no more ground truth because we can never observe the effect of being treated and not treated on a person at the same time.</em></p>
</blockquote>
<p>To answer it we deep dive into some common model diagnostic tools.</p>
<div id="perfect-uplift-prediction" class="section level3">
<h3>Perfect uplift prediction</h3>
<p>How would a perfect uplift model predict? Following <a href="http://ama.imag.fr/~amini/Publis/large-scale-benchmark.pdf">Diemert, Eustache, et.al. (2020) “A Large Scale Benchmark for Uplift Modeling”</a>,
&gt; A perfect model assigns higher scores to all treated individuals with positive outcomes than any individuals with negative outcomes.</p>
<pre class="python"><code>def perfect_uplift_model(data: DataIn):
    # control Responders
    cr_num = np.sum((data.y == 1) &amp; (data.treatment == 0))
    # treated Non-Responders
    tn_num = np.sum((data.y == 0) &amp; (data.treatment == 1))

    # compute perfect uplift curve
    summand = data.y if cr_num &gt; tn_num else data.treatment
    return 2 * (data.y == data.treatment) + summand


perfect_uplift_train = perfect_uplift_model(data=data_train)
perfect_uplift_val = perfect_uplift_model(data=data_val)
</code></pre>
<p>We can compare the sorted predictions of the models against the perfect one.</p>
<pre class="python"><code>fig, ax = plt.subplots(
    nrows=2, ncols=1, figsize=(8, 8), sharex=True, layout=&quot;constrained&quot;
)
sns.lineplot(
    x=range(data_train.y.size),
    y=np.sort(a=perfect_uplift_train)[::-1],
    color=&quot;C3&quot;,
    label=&quot;perfect model&quot;,
    ax=ax[0],
)
sns.lineplot(
    x=range(data_train.y.size),
    y=np.sort(a=data_out_train_s.y_pred.flatten())[::-1],
    color=&quot;C0&quot;,
    label=&quot;S Learner&quot;,
    ax=ax[1],
)
sns.lineplot(
    x=range(data_train.y.size),
    y=np.sort(a=data_out_train_t.y_pred.flatten())[::-1],
    color=&quot;C1&quot;,
    label=&quot;T Learner&quot;,
    ax=ax[1],
)
sns.lineplot(
    x=range(data_train.y.size),
    y=np.sort(a=data_out_train_x.y_pred.flatten())[::-1],
    color=&quot;C2&quot;,
    label=&quot;X Learner&quot;,
    ax=ax[1],
)
ax[1].set(xlabel=&quot;Number treated&quot;)
fig.suptitle(&quot;np.sort(a=uplift_prediction)[::-1] (train)&quot;);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_74_1.svg" alt="html" style="width: 800px;"/>
</center>
</div>
<div id="uplift-by-percentile" class="section level3">
<h3>Uplift by percentile</h3>
<ol style="list-style-type: decimal">
<li>Sort uplift predictions by decreasing order.</li>
<li>Predict uplift for both treated and control observations</li>
<li>Compute the average prediction per percentile in both groups.</li>
<li>The difference between those averages is taken for each percentile.</li>
</ol>
<p>This difference gives an idea of the uplift gain per percentile. One can compute this using the <code>uplift_by_percentile</code> function (from <a href="https://github.com/maks-sh/scikit-uplift/blob/master/sklift/metrics/metrics.py"><code>sklift.metrics</code></a>). Let us see how the data looks for the S learner.</p>
<pre class="python"><code>uplift_by_percentile_df = uplift_by_percentile(
    y_true=data_train.y,
    uplift=data_out_train_s.y_pred.flatten(),
    treatment=data_train.treatment,
    strategy=&quot;overall&quot;,
    total=True,
)

uplift_by_percentile_df
</code></pre>
<center>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
n_treatment
</th>
<th>
n_control
</th>
<th>
response_rate_treatment
</th>
<th>
response_rate_control
</th>
<th>
uplift
</th>
</tr>
<tr>
<th>
percentile
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0-10
</th>
<td>
7090
</td>
<td>
6862
</td>
<td>
0.612412
</td>
<td>
0.398863
</td>
<td>
0.213549
</td>
</tr>
<tr>
<th>
10-20
</th>
<td>
7024
</td>
<td>
6928
</td>
<td>
0.575456
</td>
<td>
0.478637
</td>
<td>
0.096818
</td>
</tr>
<tr>
<th>
20-30
</th>
<td>
7037
</td>
<td>
6915
</td>
<td>
0.587040
</td>
<td>
0.523644
</td>
<td>
0.063396
</td>
</tr>
<tr>
<th>
30-40
</th>
<td>
7013
</td>
<td>
6938
</td>
<td>
0.630543
</td>
<td>
0.570193
</td>
<td>
0.060350
</td>
</tr>
<tr>
<th>
40-50
</th>
<td>
7089
</td>
<td>
6862
</td>
<td>
0.665961
</td>
<td>
0.634946
</td>
<td>
0.031015
</td>
</tr>
<tr>
<th>
50-60
</th>
<td>
7019
</td>
<td>
6932
</td>
<td>
0.708790
</td>
<td>
0.688113
</td>
<td>
0.020677
</td>
</tr>
<tr>
<th>
60-70
</th>
<td>
7087
</td>
<td>
6864
</td>
<td>
0.749683
</td>
<td>
0.732226
</td>
<td>
0.017456
</td>
</tr>
<tr>
<th>
70-80
</th>
<td>
6910
</td>
<td>
7041
</td>
<td>
0.748625
</td>
<td>
0.774180
</td>
<td>
-0.025555
</td>
</tr>
<tr>
<th>
80-90
</th>
<td>
6870
</td>
<td>
7081
</td>
<td>
0.623144
</td>
<td>
0.656687
</td>
<td>
-0.033543
</td>
</tr>
<tr>
<th>
90-100
</th>
<td>
6583
</td>
<td>
7368
</td>
<td>
0.454960
</td>
<td>
0.575054
</td>
<td>
-0.120095
</td>
</tr>
<tr>
<th>
total
</th>
<td>
69722
</td>
<td>
69791
</td>
<td>
0.636743
</td>
<td>
0.603531
</td>
<td>
0.033213
</td>
</tr>
</tbody>
</table>
</div>
</center>
<p>A well performing model would have large values in the first percentiles and decreasing values for larger ones. Now we can generate the plots:</p>
<pre class="python"><code>train_pred = [data_out_train_s, data_out_train_t, data_out_train_x]

for data_out_train in train_pred:
    ax = plot_uplift_by_percentile(
        y_true=data_train.y,
        uplift=data_out_train.y_pred.flatten(),
        treatment=data_train.treatment,
        strategy=&quot;overall&quot;,
        kind=&quot;line&quot;,
    )
    ax.legend(loc=&quot;center left&quot;, bbox_to_anchor=(1, 0.5))
    fig = ax.get_figure()
    fig.suptitle(
      f&quot;In-sample predictions ({data_out_train.meta_learner_name})&quot;, y=1.1
    )
</code></pre>
<center>
<img src="../images/uplift_files/uplift_78_1.svg" alt="html" style="width: 800px;"/>
</center>
<center>
<img src="../images/uplift_files/uplift_78_2.svg" alt="html" style="width: 800px;"/>
</center>
<center>
<img src="../images/uplift_files/uplift_78_3.svg" alt="html" style="width: 800px;"/>
</center>
<pre class="python"><code>val_pred = [data_out_val_s, data_out_val_t, data_out_val_x]

for data_out_val in val_pred:
    ax = plot_uplift_by_percentile(
        y_true=data_val.y,
        uplift=data_out_val.y_pred.flatten(),
        treatment=data_val.treatment,
        strategy=&quot;overall&quot;,
        kind=&quot;line&quot;,
    )
    ax.legend(loc=&quot;center left&quot;, bbox_to_anchor=(1, 0.5))
    fig = ax.get_figure()
    fig.suptitle(
      f&quot;Out-of-sample predictions ({data_out_val.meta_learner_name})&quot;, y=1.1
    )
</code></pre>
<center>
<img src="../images/uplift_files/uplift_79_1.svg" alt="html" style="width: 800px;"/>
</center>
<center>
<img src="../images/uplift_files/uplift_79_2.svg" alt="html" style="width: 800px;"/>
</center>
<center>
<img src="../images/uplift_files/uplift_79_3.svg" alt="html" style="width: 800px;"/>
</center>
<p><strong>Remark:</strong> Here is the uplift by percentile table for the perfect model (train):</p>
<pre class="python"><code>uplift_by_percentile_df = uplift_by_percentile(
    y_true=data_train.y,
    uplift=perfect_uplift_train,
    treatment=data_train.treatment,
    strategy=&quot;overall&quot;,
    total=False,
)

uplift_by_percentile_df
</code></pre>
</center>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
n_treatment
</th>
<th>
n_control
</th>
<th>
response_rate_treatment
</th>
<th>
response_rate_control
</th>
<th>
uplift
</th>
</tr>
<tr>
<th>
percentile
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0-10
</th>
<td>
13952
</td>
<td>
0
</td>
<td>
1.0
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
10-20
</th>
<td>
13952
</td>
<td>
0
</td>
<td>
1.0
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
20-30
</th>
<td>
13952
</td>
<td>
0
</td>
<td>
1.0
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
30-40
</th>
<td>
2539
</td>
<td>
11412
</td>
<td>
1.0
</td>
<td>
0.000000
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
40-50
</th>
<td>
0
</td>
<td>
13951
</td>
<td>
NaN
</td>
<td>
0.000000
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
50-60
</th>
<td>
0
</td>
<td>
13951
</td>
<td>
NaN
</td>
<td>
0.834636
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
60-70
</th>
<td>
0
</td>
<td>
13951
</td>
<td>
NaN
</td>
<td>
1.000000
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
70-80
</th>
<td>
0
</td>
<td>
13951
</td>
<td>
NaN
</td>
<td>
1.000000
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
80-90
</th>
<td>
11376
</td>
<td>
2575
</td>
<td>
0.0
</td>
<td>
1.000000
</td>
<td>
-1.0
</td>
</tr>
<tr>
<th>
90-100
</th>
<td>
13951
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
</tbody>
</table>
</div>
</center>
</div>
<div id="cumulative-gain-chart" class="section level3">
<h3>Cumulative gain chart</h3>
<blockquote>
<p><em>Predict uplift for both treated and control observations and compute the average prediction per decile (bins) in both groups. Then, the difference between those averages is taken for each decile.</em> (<a href="https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf">Gutierrez, P., &amp; Gérardy, J. Y. (2017). <em>“Causal Inference and Uplift Modelling: A Review of the Literature”</em></a>)</p>
</blockquote>
<p><span class="math display">\[
\left(
\frac{Y^{T}}{N^{T}}
-
\frac{Y^{C}}{N^{C}}
\right)
(N^{T} + N^{C})
\]</span></p>
<blockquote>
<ul>
<li><span class="math inline">\(Y^{T} / Y^{C}\)</span>: sum of the treated / control individual outcomes in the bin.</li>
<li><span class="math inline">\(N^{T} / N^{C}\)</span>: number of treated / control observations in the bin.</li>
</ul>
</blockquote>
<p>We can compute this from the tables above. For example, for the S learner:</p>
<pre class="python"><code>uplift_by_percentile_df = uplift_by_percentile(
    y_true=data_train.y,
    uplift=data_out_train_s.y_pred.flatten(),
    treatment=data_train.treatment,
    strategy=&quot;overall&quot;,
    total=False,
)


def compute_response_absolutes(df: pd.DataFrame) -&gt; pd.DataFrame:
    df[&quot;responses_treatment&quot;] = df[&quot;n_treatment&quot;] * df[&quot;response_rate_treatment&quot;]
    df[&quot;responses_control&quot;] = df[&quot;n_control&quot;] * df[&quot;response_rate_control&quot;]
    return df


def compute_cumulative_response_rates(df: pd.DataFrame) -&gt; pd.DataFrame:
    df[&quot;n_treatment_cumsum&quot;] = df[&quot;n_treatment&quot;].cumsum()
    df[&quot;n_control_cumsum&quot;] = df[&quot;n_control&quot;].cumsum()
    df[&quot;responses_treatment_cumsum&quot;] = df[&quot;responses_treatment&quot;].cumsum()
    df[&quot;responses_control_cumsum&quot;] = df[&quot;responses_control&quot;].cumsum()
    df[&quot;response_rate_treatment_cumsum&quot;] = (
        df[&quot;responses_treatment_cumsum&quot;] / df[&quot;n_treatment_cumsum&quot;]
    )
    df[&quot;response_rate_control_cumsum&quot;] = (
        df[&quot;responses_control_cumsum&quot;] / df[&quot;n_control_cumsum&quot;]
    )
    return df


def compute_cumulative_gain(df: pd.DataFrame) -&gt; pd.DataFrame:
    df[&quot;uplift_cumsum&quot;] = (
        df[&quot;response_rate_treatment_cumsum&quot;] - df[&quot;response_rate_control_cumsum&quot;]
    )
    df[&quot;cum_gain&quot;] = df[&quot;uplift_cumsum&quot;] * (
        df[&quot;n_treatment_cumsum&quot;] + df[&quot;n_control_cumsum&quot;]
    )
    return df


fig, ax = plt.subplots()

uplift_by_percentile_df \
  .pipe(compute_response_absolutes) \
  .pipe(compute_cumulative_response_rates) \
  .pipe(compute_cumulative_gain) \
  .plot(y=&quot;cum_gain&quot;, kind=&quot;line&quot;, marker=&quot;o&quot;, ax=ax)
ax.legend().remove()
ax.set(
    title=&quot;Cumulative gain by percentile - S Learned (train)&quot;,
    ylabel=&quot;cumulative gain&quot;
);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_84_1.svg" alt="html" style="width: 800px;"/>
</center>
<p><strong>Remark:</strong> From <a href="https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf">Gutierrez, P., &amp; Gérardy, J. Y. (2017). <em>“Causal Inference and Uplift Modelling: A Review of the Literature”</em></a>,
&gt; This is useful to marketers because they can easily see if the treatment has a global positive or negative effect and if they can expect a better gain by targeting part of the population. We can thus choose the decile that maximizes the gain as the limit of the population to be targeted.</p>
</div>
<div id="uplift-curve" class="section level3">
<h3>Uplift Curve</h3>
<blockquote>
<p><em>We can generalize the cumulative gain chart for each observation of the test set:</em></p>
</blockquote>
<p><span class="math display">\[
f(t)
=
\left(
\frac{Y^{T}_{t}}{N^{T}_{t}}
-
\frac{Y^{C}_{t}}{N^{C}_{t}}
\right)
(N^{T}_{t} + N^{C}_{t})
\]</span></p>
<blockquote>
<p><em>where the <span class="math inline">\(t\)</span> subscript indicates that the quantity is calculated for the first <span class="math inline">\(t\)</span> observations, sorted by inferred uplift value.</em> (<a href="https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf">Gutierrez, P., &amp; Gérardy, J. Y. (2017). “Causal Inference and Uplift Modelling: A Review of the Literature”</a>)</p>
</blockquote>
<pre class="python"><code>fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 15), layout=&quot;constrained&quot;)
# in-sample
for i, data_out_train in enumerate(train_pred):
    ax = axes[i, 0]
    plot_uplift_curve(
        y_true=data_train.y,
        uplift=data_out_train.y_pred.flatten(),
        treatment=data_train.treatment,
        perfect=True,
        ax=ax,
    )
    ax.set(title=f&quot;In-sample predictions ({data_out_train.meta_learner_name})&quot;)

# out-of-sample
for j, data_out_val in enumerate(val_pred):
    ax = axes[j, 1]
    plot_uplift_curve(
        y_true=data_val.y,
        uplift=data_out_val.y_pred.flatten(),
        treatment=data_val.treatment,
        perfect=True,
        ax=ax,
    )
    ax.set(title=f&quot;Out-sample predictions ({data_out_val.meta_learner_name})&quot;)

fig.suptitle(&quot;Uplift Curves&quot;, fontsize=24);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_87_1.svg" alt="html" style="width: 1000px;"/>
</center>
<p><strong>A remark on the perfect uplift curve:</strong> (<a href="http://ama.imag.fr/~amini/Publis/large-scale-benchmark.pdf">Diemert, Eustache, et.al. (2020) “A Large Scale Benchmark for Uplift Modeling”</a>)
&gt; A perfect model assigns higher scores to all treated individuals
with positive outcomes than any individuals with negative outcomes.</p>
<pre class="python"><code>from sklift.metrics import uplift_curve

num_all, curve_values = uplift_curve(
    y_true=data_train.y, uplift=perfect_uplift_train, treatment=data_train.treatment
)

fig, ax1 = plt.subplots(figsize=(8, 6))
ax2 = ax1.twinx()
sns.lineplot(
    x=num_all,
    y=curve_values,
    color=&quot;C2&quot;,
    marker=&quot;o&quot;,
    markersize=10,
    label=&quot;perfect uplift curve&quot;,
    ax=ax1,
)
sns.lineplot(
    x=range(data_train.y.size),
    y=np.sort(a=perfect_uplift_train)[::-1],
    color=&quot;C3&quot;,
    label=&quot;np.sort(a=perfect_uplift_train)[::-1]&quot;,
    ax=ax2,
)
ax1.legend(loc=&quot;upper center&quot;, bbox_to_anchor=(0.5, -0.12), ncol=1)
ax1.set(
    xlabel=&quot;Number targeted&quot;,
    ylabel=&quot;Number of incremental outcome&quot;,
    title=&quot;Perfect Uplift Curve&quot;,
)
ax2.grid(None)
ax2.legend(loc=&quot;upper center&quot;, bbox_to_anchor=(0.5, -0.20), ncol=1);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_89_1.svg" alt="html" style="width: 800px;"/>
</center>
<p>We can compare the perfect uplift curve against a random one:</p>
<pre class="python"><code># number of random uplift curves to generate
n_random_samples = 100
# sample random uplift curves from a uniform distribution
uplift_random_samples = np.random.uniform(
    low=-1,
    high=1,
    size=(data_train.y.size, n_random_samples),
)
# compute uplift curve for each random sample
random_uplift_curves = [
    uplift_curve(
        y_true=data_train.y,
        uplift=uplift_random_samples[:, i],
        treatment=data_train.treatment,
    )
    for i in range(n_random_samples)
]

# plot
fig, ax = plt.subplots(
    nrows=2, ncols=1, figsize=(8, 10), sharex=True, layout=&quot;constrained&quot;
)
# perfect uplift curve
sns.lineplot(
    x=num_all,
    y=curve_values,
    color=&quot;C2&quot;,
    marker=&quot;o&quot;,
    markersize=10,
    label=&quot;perfect uplift curve&quot;,
    ax=ax[1],
)
# random uplift curves
for x, y in random_uplift_curves:
    ax[0].plot(x, y, color=&quot;C1&quot;, alpha=0.05)
    ax[1].plot(x, y, color=&quot;C1&quot;, alpha=0.05)
ax[0].set(title=&quot;Random Uplift Curves&quot;, ylabel=&quot;Number of incremental outcome&quot;)
ax[1].set(xlabel=&quot;Number targeted&quot;, ylabel=&quot;Number of incremental outcome&quot;);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_91_1.svg" alt="html" style="width: 800px;"/>
</center>
</div>
<div id="qini-curve" class="section level3">
<h3>Qini Curve</h3>
<p>There is another variant for measuring the uplift, the <em>Qini curve</em>. It is defined as follows:</p>
<p><span class="math display">\[
g(t)
=
Y^{T}_{t}
-
Y^{C}_{t}
\left(
\frac{N^{T}_{t}}{N^{C}_{t}}
\right)
\]</span></p>
<pre class="python"><code>fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 15), layout=&quot;constrained&quot;)
# in-sample
for i, data_out_train in enumerate(train_pred):
    ax = axes[i, 0]
    plot_qini_curve(
        y_true=data_train.y,
        uplift=data_out_train.y_pred.flatten(),
        treatment=data_train.treatment,
        perfect=True,
        ax=ax,
    )
    ax.set(title=f&quot;In-sample predictions ({data_out_train.meta_learner_name})&quot;)

# out-of-sample
for j, data_out_val in enumerate(val_pred):
    ax = axes[j, 1]
    plot_qini_curve(
        y_true=data_val.y,
        uplift=data_out_val.y_pred.flatten(),
        treatment=data_val.treatment,
        perfect=True,
        ax=ax,
    )
    ax.set(title=f&quot;Out-sample predictions ({data_out_val.meta_learner_name})&quot;)

fig.suptitle(&quot;Qini Curves&quot;, fontsize=24);
</code></pre>
<center>
<img src="../images/uplift_files/uplift_93_1.svg" alt="html" style="width: 1000px;"/>
</center>
<p>For more details on the Qini curve an related metrics see Section 4 in <a href="http://ama.imag.fr/~amini/Publis/large-scale-benchmark.pdf">Diemert, Eustache, et.al. (2020) <em>“A Large Scale Benchmark for Uplift Modeling”</em></a>.</p>
</div>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/dockerfile.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-122570825-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

