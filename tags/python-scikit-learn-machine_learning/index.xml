<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python, scikit-learn, machine_learning on Dr. Juan Camilo Orduz</title>
    <link>/tags/python-scikit-learn-machine_learning/</link>
    <description>Recent content in python, scikit-learn, machine_learning on Dr. Juan Camilo Orduz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/python-scikit-learn-machine_learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Feature Engineering: patsy as FormulaTransformer</title>
      <link>/formula_transformer/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/formula_transformer/</guid>
      <description>In this notebook I want to describe how to create features inside scikit-learn pipelines using patsy-like formulas. I have used this approach to generate features in a previous post: GLM in PyMC3: Out-Of-Sample Predictions, so I will consider the same data set here for the sake of comparison.
Prepare Notebook import matplotlib.pyplot as plt import numpy as np import pandas as pd import patsy import seaborn as sns from sklearn.</description>
    </item>
    
  </channel>
</rss>
