<!DOCTYPE html>
<html lang="en-us">
  <head>
    <script defer src="https://use.fontawesome.com/releases/v5.13.0/js/all.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-5NM5EDH834"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5NM5EDH834');
</script>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.1" />


<title>PyData Berlin 2019: Gaussian Processes for Time Series Forecasting (scikit-learn) - Dr. Juan Camilo Orduz</title>
<meta property="og:title" content="PyData Berlin 2019: Gaussian Processes for Time Series Forecasting (scikit-learn) - Dr. Juan Camilo Orduz">


  <link href='../images/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/sphere2.gif"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../about/"> About</a></li>
    
    <li><a href="https://github.com/juanitorduz"><i class='fab fa-github fa-2x'></i>  </a></li>
    
    <li><a href="https://www.linkedin.com/in/juanitorduz/"><i class='fab fa-linkedin fa-2x' style='color:#0077B5;'></i>  </a></li>
    
    <li><a href="https://twitter.com/juanitorduz"><i class='fab fa-twitter fa-2x' style='color:#1DA1F2;'></i>  </a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">PyData Berlin 2019: Gaussian Processes for Time Series Forecasting (scikit-learn)</h1>

    
    <span class="article-date">2019-10-10</span>
    

    <div class="article-content">
      
<script src="../rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>In this notebook we run some experiments to demonstrate how we can use Gaussian Processes in the context of time series forecasting with <a href="https://scikit-learn.org/stable/modules/gaussian_process.html">scikit-learn</a>. This material is part of a talk on <a href="https://de.pycon.org/program/pydata-knlnbb-gaussian-process-for-time-series-analysis-dr-juan-orduz/">Gaussian Process for Time Series Analysis</a> presented at the <a href="https://de.pycon.org/">PyCon DE &amp; PyData 2019 Conference</a> in Berlin.</p>
<p><strong>Update:</strong> Additional material and plots were included for the <a href="http://www.fields.utoronto.ca/activities/20-21/dynamical">Second Symposium on Machine Learning and Dynamical Systems</a> at <a href="http://www.fields.utoronto.ca/">The Fields Institute</a> (virtual event).</p>
<p><strong>Videos</strong></p>
<ul>
<li>PyData Berlin 2019</li>
</ul>
<center>
<iframe width="500" height="300" src="https://www.youtube.com/embed/0p_6RzhSZEc?rel=0" frameborder="0" allowfullscreen>
</iframe>
</center>
<ul>
<li>Second Symposium on Machine Learning and Dynamical Systems 2020</li>
</ul>
<center>
<iframe width="500" height="300" src="https://www.youtube.com/embed/n42uQjhoS9g" frameborder="0" allowfullscreen>
</iframe>
</center>
<p><strong>Slides</strong></p>
<p><a href="../documents/orduz_pydata2019.pdf">Here</a> you can find the slides of the talk.</p>
<p>Suggestions and comments are always welcome!</p>
<p><strong>References:</strong></p>
<ul>
<li><a href="http://www.gaussianprocess.org/gpml/">Gaussian Processes for Machine Learning</a>, by Carl Edward Rasmussen and Christopher K. I. Williams.</li>
<li><a href="http://www.robots.ox.ac.uk/~sjrob/Pubs/philTransA_2012.pdf">Gaussian Processes for Timeseries Modelling</a>, by S. Roberts, M. Osborne, M. Ebden, S. Reece, N. Gibson2 and S. Aigrain.</li>
<li><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a>, by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.</li>
<li><a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a>, by Richard McElreath.</li>
<li><a href="https://scikit-learn.org/stable/modules/gaussian_process.html">scikit-learn docs: 1.7. Gaussian Processes</a>. In particular I recommend the example: <a href="https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_co2.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-co2-py">Gaussian process regression (GPR) on Mauna Loa CO2 data</a>.</li>
<li>Blog Posts:
<ul>
<li><a href="https://juanitorduz.github.io/reg_bayesian_regression/">Bayesian Regression as a Gaussian Process</a></li>
<li><a href="https://juanitorduz.github.io/gaussian_process_reg/">An Introduction to Gaussian Process Regression</a></li>
</ul></li>
</ul>
<div id="prepare-notebook" class="section level2">
<h2>Prepare Notebook</h2>
<pre class="python"><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import seaborn as sns
sns.set_style(
    style=&#39;darkgrid&#39;, 
    rc={&#39;axes.facecolor&#39;: &#39;.9&#39;, &#39;grid.color&#39;: &#39;.8&#39;}
)
sns.set_palette(palette=&#39;deep&#39;)
sns_c = sns.color_palette(palette=&#39;deep&#39;)
%matplotlib inline
plt.rcParams[&#39;figure.figsize&#39;] = [12, 6]
plt.rcParams[&#39;figure.dpi&#39;] = 100</code></pre>
</div>
<div id="example-1" class="section level2">
<h2>Example 1</h2>
<p>In this first example we consider a seasonal stationary time series.</p>
<div id="generate-data" class="section level3">
<h3>Generate Data</h3>
<ul>
<li>Time Variable</li>
</ul>
<p>Let us define a “time” variable <span class="math inline">\(t\in \mathbb{N}\)</span>.</p>
<pre class="python"><code># Number of samples. 
n = 1000
# Generate &quot;time&quot; variable. 
t = np.arange(n)

data_df = pd.DataFrame({&#39;t&#39; : t})</code></pre>
<ul>
<li>Seasonal Component</li>
</ul>
<p>Let us define a function to generate seasonal components (Fourier modes).</p>
<pre class="python"><code># Generate seasonal variables. 
def seasonal(t, amplitude, period):
    &quot;&quot;&quot;Generate a sinusoidal curve.&quot;&quot;&quot;
    y1 = amplitude * np.sin((2*np.pi)*t/period) 
    return y1

# Add two seasonal components. 
data_df[&#39;s1&#39;] = data_df[&#39;t&#39;].apply(lambda t : seasonal(t, amplitude=2, period=40))

# Define target variable. 
data_df[&#39;y1&#39;] = data_df[&#39;s1&#39;]</code></pre>
<p>Let us plot this seasonal variable:</p>
<pre class="python"><code>fig, ax = plt.subplots()
sns.lineplot(x=&#39;t&#39;, y=&#39;s1&#39;, data=data_df, color=sns_c[0], label=&#39;s1&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Seasonal Component&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_9_0.svg" title="fig:" alt="svg" />
</center>
<ul>
<li>Gaussian Noise</li>
</ul>
<p>Finally, we add some noise.</p>
<pre class="python"><code># Set noise standard deviation. 
sigma_n = 0.3

data_df[&#39;epsilon&#39;] = np.random.normal(loc=0, scale=sigma_n, size=n)
# Add noise to target variable. 
data_df [&#39;y1&#39;] = data_df [&#39;y1&#39;] + data_df [&#39;epsilon&#39;]</code></pre>
<p>Let us plot the resulting data:</p>
<pre class="python"><code>fig, ax = plt.subplots()
sns.lineplot(x=&#39;t&#39;, y=&#39;y1&#39;, data=data_df, color=sns_c[0], label=&#39;y1&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Sample Data 1&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_13_0.svg" title="fig:" alt="svg" />
</center>
</div>
<div id="define-model" class="section level3">
<h3>Define Model</h3>
<p>Let us now define the kernel of the gaussian process model. We include the following kernel components (<a href="http://www.gaussianprocess.org/gpml/chapters/RW4.pdf">recall</a> that the sum of kernels is again a kernel):</p>
<ul>
<li><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.html"><code>WhiteKernel</code></a> to account for noise.</p></li>
<li><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared.html"><code>ExpSineSquared</code></a> to model the periodic component.</p></li>
</ul>
<p>We add bounds to the kernel hyper-parameters which are optimized by maximizing the log-marginal-likelihood (see <a href="https://scikit-learn.org/stable/modules/gaussian_process.html">documentation</a>).</p>
<pre class="python"><code>from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, ConstantKernel

k0 = WhiteKernel(noise_level=0.3**2, noise_level_bounds=(0.1**2, 0.5**2))

k1 = ConstantKernel(constant_value=2) * \
  ExpSineSquared(length_scale=1.0, periodicity=40, periodicity_bounds=(35, 45))

kernel_1  = k0 + k1 </code></pre>
<p>Next we initialize the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor"><code>GaussianProcessRegressor</code></a> object.</p>
<pre class="python"><code>from sklearn.gaussian_process import GaussianProcessRegressor

gp1 = GaussianProcessRegressor(
    kernel=kernel_1, 
    n_restarts_optimizer=10, 
    normalize_y=True,
    alpha=0.0
)</code></pre>
</div>
<div id="split-data" class="section level3">
<h3>Split Data</h3>
<p>We now prepare and split the data for the model.</p>
<pre class="python"><code>X = data_df[&#39;t&#39;].values.reshape(n, 1)
y = data_df[&#39;y1&#39;].values.reshape(n, 1)

prop_train = 0.7
n_train = round(prop_train * n)

X_train = X[:n_train]
y_train = y[:n_train]

X_test = X[n_train:]
y_test = y[n_train:]</code></pre>
</div>
<div id="prior-sampling" class="section level3">
<h3>Prior Sampling</h3>
<p>Let us sample from the prior distribution and compare it with our given data.</p>
<pre class="python"><code>gp1_prior_samples = gp1.sample_y(X=X_train, n_samples=100)

fig, ax = plt.subplots()
for i in range(100):
    sns.lineplot(x=X_train[...,0], y = gp1_prior_samples[:, i], color=sns_c[1], alpha=0.2, ax=ax)
sns.lineplot(x=X_train[...,0], y=y_train[..., 0], color=sns_c[0], label=&#39;y1&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;GP1 Prior Samples&#39;, xlabel=&#39;t&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_22_0.svg" title="fig:" alt="svg" />
</center>
<p>We indeed see the prior specification seems plausible for this model.</p>
</div>
<div id="model-fit-predictions" class="section level3">
<h3>Model Fit + Predictions</h3>
<p>Let us fit the model and generate predictions.</p>
<pre class="python"><code>gp1.fit(X_train, y_train)</code></pre>
<pre><code>GaussianProcessRegressor(alpha=0.0,
                         kernel=WhiteKernel(noise_level=0.09) + 1.41**2 * ExpSineSquared(length_scale=1, periodicity=40),
                         n_restarts_optimizer=10, normalize_y=True)</code></pre>
<pre class="python"><code># Generate predictions.
y_pred, y_std = gp1.predict(X, return_std=True)

data_df[&#39;y_pred&#39;] = y_pred
data_df[&#39;y_std&#39;] = y_std
data_df[&#39;y_pred_lwr&#39;] = data_df[&#39;y_pred&#39;] - 2*data_df[&#39;y_std&#39;]
data_df[&#39;y_pred_upr&#39;] = data_df[&#39;y_pred&#39;] + 2*data_df[&#39;y_std&#39;]</code></pre>
<p>We plot the predictions.</p>
<pre class="python"><code>fig, ax = plt.subplots()

ax.fill_between(
    x=data_df[&#39;t&#39;], 
    y1=data_df[&#39;y_pred_lwr&#39;], 
    y2=data_df[&#39;y_pred_upr&#39;], 
    color=sns_c[2], 
    alpha=0.15, 
    label=&#39;credible_interval&#39;
)

sns.lineplot(x=&#39;t&#39;, y=&#39;y1&#39;, data=data_df, color=sns_c[0], label = &#39;y1&#39;, ax=ax)
sns.lineplot(x=&#39;t&#39;, y=&#39;y_pred&#39;, data=data_df, color=sns_c[2], label=&#39;y_pred&#39;, ax=ax)

ax.axvline(n_train, color=sns_c[3], linestyle=&#39;--&#39;, label=&#39;train-test split&#39;)
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Prediction Sample 1&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_28_0.svg" title="fig:" alt="svg" />
</center>
<p>Let us compute the <span class="math inline">\(R^2\)</span> (coefficient of determination, which can be negative) and the Mean Absolute Error of the prediction on the train and test set.</p>
<pre class="python"><code>from sklearn.metrics import mean_absolute_error
print(f&#39;R2 Score Train = {gp1.score(X=X_train, y=y_train): 0.3f}&#39;)
print(f&#39;R2 Score Test = {gp1.score(X=X_test, y=y_test): 0.3f}&#39;)
print(f&#39;MAE Train = {mean_absolute_error(y_true=y_train, y_pred=gp1.predict(X_train)): 0.3f}&#39;)
print(f&#39;MAE Test = {mean_absolute_error(y_true=y_test, y_pred=gp1.predict(X_test)): 0.3f}&#39;)</code></pre>
<pre><code>R2 Score Train =  0.961
R2 Score Test =  0.960
MAE Train =  0.228
MAE Test =  0.236</code></pre>
</div>
<div id="errors" class="section level3">
<h3>Errors</h3>
<pre class="python"><code>errors = gp1.predict(X_test) - y_test
errors = errors.flatten()
errors_mean = errors.mean()
errors_std = errors.std()

fig, ax = plt.subplots(1, 2, figsize=(12, 6)) 
sns.regplot(x=y_test.flatten(), y=gp1.predict(X_test).flatten(), ax=ax[0])
sns.distplot(a=errors, ax=ax[1])
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;, label=f&#39;$\mu$&#39;)
ax[1].axvline(x=errors_mean + 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;, label=f&#39;$\mu \pm 2\sigma$&#39;)
ax[1].axvline(x=errors_mean - 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;)
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;)
ax[1].legend()
ax[0].set(title=&#39;Model 1 - Test vs Predictions (Test Set)&#39;, xlabel=&#39;y_test&#39;, ylabel=&#39;y_pred&#39;);
ax[1].set(title=&#39;Model 1  - Errors&#39;, xlabel=&#39;error&#39;, ylabel=None);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_32_0.svg" title="fig:" alt="svg" />
<center>
</div>
</div>
<div id="example-2" class="section level2">
<h2>Example 2</h2>
<p>In this example we add a linear trend component.</p>
<ul>
<li>Linear Trend Component</li>
</ul>
<pre class="python"><code># Generate trend component. 
def linear_trend(beta, x):
    &quot;&quot;&quot;Scale vector by a scalar.&quot;&quot;&quot;
    trend_comp = beta * x 
    return trend_comp

data_df[&#39;tr1&#39;] = data_df[&#39;t&#39;].apply(lambda x : linear_trend(0.01, x))

# Add trend to target variable y_1. 
data_df[&#39;y2&#39;] = data_df[&#39;y1&#39;] + data_df[&#39;tr1&#39;]</code></pre>
<p>Let us see the trend plot:</p>
<pre class="python"><code>fig, ax = plt.subplots()
sns.lineplot(x=&#39;t&#39;, y=&#39;y2&#39;, data=data_df, color=sns_c[0], label=&#39;y2&#39;, ax=ax)
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Sample Data 2&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_37_0.svg" title="fig:" alt="svg" />
</center>
<div id="define-model-1" class="section level3">
<h3>Define Model</h3>
<p>For this second example we add a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html"><code>RBF</code></a> kernel to model the trend component.</p>
<pre class="python"><code>from sklearn.gaussian_process.kernels import RBF

k0 = WhiteKernel(noise_level=0.3**2, noise_level_bounds=(0.1**2, 0.5**2))

k1 = ConstantKernel(constant_value=12) * \
  ExpSineSquared(length_scale=1.0, periodicity=40, periodicity_bounds=(35, 45))

k2 = ConstantKernel(constant_value=10, constant_value_bounds=(1e-2, 1e3)) * \
  RBF(length_scale=1e2, length_scale_bounds=(1, 1e3)) 

kernel_2  = k0 + k1 + k2</code></pre>
<pre class="python"><code># Define GaussianProcessRegressor object. 
gp2 = GaussianProcessRegressor(
    kernel=kernel_2, 
    n_restarts_optimizer=10, 
    normalize_y=True,
    alpha=0.0
)</code></pre>
</div>
<div id="split-data-1" class="section level3">
<h3>Split Data</h3>
<p>We split the data as above.</p>
<pre class="python"><code>y = data_df[&#39;y2&#39;].values.reshape(n, 1)
y_train = y[:n_train]
y_test = y[n_train:]</code></pre>
</div>
<div id="prior-sampling-1" class="section level3">
<h3>Prior Sampling</h3>
<pre class="python"><code>gp2_prior_samples = gp2.sample_y(X=X_train, n_samples=100)

fig, ax = plt.subplots()
for i in range(100):
    sns.lineplot(x=X_train[...,0], y = gp2_prior_samples[:, i], color=sns_c[1], alpha=0.2, ax=ax)
sns.lineplot(x=X_train[...,0], y=y_train[..., 0], color=sns_c[0], label=&#39;y2&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;GP2 Prior Samples&#39;, xlabel=&#39;t&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_44_0.svg" title="fig:" alt="svg" />
</center>
</div>
<div id="model-fit-predictions-1" class="section level3">
<h3>Model Fit + Predictions</h3>
<pre class="python"><code>gp2.fit(X_train, y_train)</code></pre>
<pre><code>GaussianProcessRegressor(alpha=0.0,
                         kernel=WhiteKernel(noise_level=0.09) + 3.46**2 * ExpSineSquared(length_scale=1, periodicity=40) + 3.16**2 * RBF(length_scale=100),
                         n_restarts_optimizer=10, normalize_y=True)</code></pre>
<pre class="python"><code># Generate predictions.
y_pred, y_std = gp2.predict(X, return_std=True)

data_df[&#39;y_pred&#39;] = y_pred
data_df[&#39;y_std&#39;] = y_std
data_df[&#39;y_pred_lwr&#39;] = data_df[&#39;y_pred&#39;] - 2*data_df[&#39;y_std&#39;]
data_df[&#39;y_pred_upr&#39;] = data_df[&#39;y_pred&#39;] + 2*data_df[&#39;y_std&#39;]</code></pre>
<p>We plot the predictions.</p>
<pre class="python"><code>fig, ax = plt.subplots()

ax.fill_between(
    x=data_df[&#39;t&#39;], 
    y1=data_df[&#39;y_pred_lwr&#39;], 
    y2=data_df[&#39;y_pred_upr&#39;], 
    color=sns_c[2], 
    alpha=0.15, 
    label=&#39;credible_interval&#39;
)

sns.lineplot(x=&#39;t&#39;, y=&#39;y2&#39;, data=data_df, color=sns_c[0], label = &#39;y2&#39;, ax=ax)
sns.lineplot(x=&#39;t&#39;, y=&#39;y_pred&#39;, data=data_df, color=sns_c[2], label=&#39;y_pred&#39;, ax=ax)

ax.axvline(n_train, color=sns_c[3], linestyle=&#39;--&#39;, label=&#39;train-test split&#39;)
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Prediction Sample 2&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_49_0.svg" title="fig:" alt="svg" />
</center>
<p>Let us compute the metrics:</p>
<pre class="python"><code>print(f&#39;R2 Score Train = {gp2.score(X=X_train, y=y_train): 0.3f}&#39;)
print(f&#39;R2 Score Test = {gp2.score(X=X_test, y=y_test): 0.3f}&#39;)
print(f&#39;MAE Train = {mean_absolute_error(y_true=y_train, y_pred=gp2.predict(X_train)): 0.3f}&#39;)
print(f&#39;MAE Test = {mean_absolute_error(y_true=y_test, y_pred=gp2.predict(X_test)): 0.3f}&#39;)</code></pre>
<pre><code>R2 Score Train =  0.987
R2 Score Test =  0.958
MAE Train =  0.229
MAE Test =  0.274</code></pre>
<pre class="python"><code>errors = gp2.predict(X_test) - y_test
errors = errors.flatten()
errors_mean = errors.mean()
errors_std = errors.std()

fig, ax = plt.subplots(1, 2, figsize=(12, 6)) 
sns.regplot(x=y_test.flatten(), y=gp2.predict(X_test).flatten(), ax=ax[0])
sns.distplot(a=errors, ax=ax[1])
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;, label=f&#39;$\mu$&#39;)
ax[1].axvline(x=errors_mean + 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;, label=f&#39;$\mu \pm 2\sigma$&#39;)
ax[1].axvline(x=errors_mean - 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;)
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;)
ax[1].legend()
ax[0].set(title=&#39;Model 2 - Test vs Predictions (Test Set)&#39;, xlabel=&#39;y_test&#39;, ylabel=&#39;y_pred&#39;);
ax[1].set(title=&#39;Model 2  - Errors&#39;, xlabel=&#39;error&#39;, ylabel=None);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_52_0.svg" title="fig:" alt="svg" />
</center>
</div>
</div>
<div id="example-3" class="section level2">
<h2>Example 3</h2>
<p>In this third example we add a second seasonal component.</p>
<ul>
<li>Add Other Seasonal Component</li>
</ul>
<pre class="python"><code># Create other seasonal component.
data_df[&#39;s2&#39;] = data_df[&#39;t&#39;].apply(lambda t : seasonal(t, amplitude=1, period=13.3))
# Add to y_2.
data_df[&#39;y3&#39;] = data_df[&#39;y2&#39;] + data_df[&#39;s2&#39;] </code></pre>
<pre class="python"><code>fig, ax = plt.subplots()
sns.lineplot(x=&#39;t&#39;, y=&#39;y3&#39;, data=data_df, color=sns_c[0], label=&#39;y3&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Sample Data 3&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_56_0.svg" title="fig:" alt="svg" />
</center>
<div id="define-model-2" class="section level3">
<h3>Define Model</h3>
<p>We add another <code>ExpSineSquared</code> kernel to the one of Example 2.</p>
<pre class="python"><code>k0 = WhiteKernel(noise_level=0.3**2, noise_level_bounds=(0.1**2, 0.5**2))

k1 = ConstantKernel(constant_value=2) * \
  ExpSineSquared(length_scale=1.0, periodicity=40, periodicity_bounds=(35, 45))

k2 = ConstantKernel(constant_value=25, constant_value_bounds=(1e-2, 1e3)) * \
  RBF(length_scale=100.0, length_scale_bounds=(1, 1e4)) 

k3 = ConstantKernel(constant_value=1) * \
  ExpSineSquared(length_scale=1.0, periodicity=12, periodicity_bounds=(10, 15))

kernel_3  = k0 + k1 + k2 + k3</code></pre>
<pre class="python"><code># Define GaussianProcessRegressor object. 
gp3 = GaussianProcessRegressor(
    kernel=kernel_3, 
    n_restarts_optimizer=10, 
    normalize_y=True,
    alpha=0.0
)</code></pre>
</div>
<div id="split-data-2" class="section level3">
<h3>Split Data</h3>
<pre class="python"><code>y = data_df[&#39;y3&#39;].values.reshape(n, 1)
y_train = y[:n_train]
y_test = y[n_train:]</code></pre>
</div>
<div id="prior-sampling-2" class="section level3">
<h3>Prior Sampling</h3>
<pre class="python"><code>gp3_prior_samples = gp3.sample_y(X=X_train, n_samples=100)

fig, ax = plt.subplots()
for i in range(100):
    sns.lineplot(x=X_train[...,0], y = gp3_prior_samples[:, i], color=sns_c[1], alpha=0.2, ax=ax)
sns.lineplot(x=X_train[...,0], y=y_train[..., 0], color=sns_c[0], label=&#39;y3&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;GP3 Prior Samples&#39;, xlabel=&#39;t&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_63_0.svg" title="fig:" alt="svg" />
</center>
</div>
<div id="model-fit-predictions-2" class="section level3">
<h3>Model Fit + Predictions</h3>
<pre class="python"><code>gp3.fit(X_train, y_train)</code></pre>
<pre><code>GaussianProcessRegressor(alpha=0.0,
                         kernel=WhiteKernel(noise_level=0.09) + 1.41**2 * ExpSineSquared(length_scale=1, periodicity=40) + 5**2 * RBF(length_scale=100) + 1**2 * ExpSineSquared(length_scale=1, periodicity=12),
                         n_restarts_optimizer=10, normalize_y=True)</code></pre>
<pre class="python"><code>y_pred, y_std = gp3.predict(X, return_std=True)

data_df[&#39;y_pred&#39;] = y_pred
data_df[&#39;y_std&#39;] = y_std
data_df[&#39;y_pred_lwr&#39;] = data_df[&#39;y_pred&#39;] - 2*data_df[&#39;y_std&#39;]
data_df[&#39;y_pred_upr&#39;] = data_df[&#39;y_pred&#39;] + 2*data_df[&#39;y_std&#39;]</code></pre>
<p>We plot the predictions:</p>
<pre class="python"><code>fig, ax = plt.subplots()

ax.fill_between(
    x=data_df[&#39;t&#39;], 
    y1=data_df[&#39;y_pred_lwr&#39;], 
    y2=data_df[&#39;y_pred_upr&#39;], 
    color=sns_c[2], 
    alpha=0.15, 
    label=&#39;credible_interval&#39;
)

sns.lineplot(x=&#39;t&#39;, y=&#39;y3&#39;, data=data_df, color=sns_c[0], label = &#39;y3&#39;, ax=ax)
sns.lineplot(x=&#39;t&#39;, y=&#39;y_pred&#39;, data=data_df, color=sns_c[2], label=&#39;y_pred&#39;, ax=ax)

ax.axvline(n_train, color=sns_c[3], linestyle=&#39;--&#39;, label=&#39;train-test split&#39;)
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Prediction Sample Data 3&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_68_0.svg" title="fig:" alt="svg" />
</center>
<pre class="python"><code>print(f&#39;R2 Score Train = {gp3.score(X=X_train, y=y_train): 0.3f}&#39;)
print(f&#39;R2 Score Test = {gp3.score(X=X_test, y=y_test): 0.3f}&#39;)
print(f&#39;MAE Train = {mean_absolute_error(y_true=y_train, y_pred=gp3.predict(X_train)): 0.3f}&#39;)
print(f&#39;MAE Test = {mean_absolute_error(y_true=y_test, y_pred=gp3.predict(X_test)): 0.3f}&#39;)</code></pre>
<pre><code>R2 Score Train =  0.989
R2 Score Test =  0.960
MAE Train =  0.211
MAE Test =  0.293</code></pre>
</div>
<div id="errors-1" class="section level3">
<h3>Errors</h3>
<pre class="python"><code>errors = gp3.predict(X_test) - y_test
errors = errors.flatten()
errors_mean = errors.mean()
errors_std = errors.std()

fig, ax = plt.subplots(1, 2, figsize=(12, 6)) 
sns.regplot(x=y_test.flatten(), y=gp3.predict(X_test).flatten(), ax=ax[0])
sns.distplot(a=errors, ax=ax[1])
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;, label=f&#39;$\mu$&#39;)
ax[1].axvline(x=errors_mean + 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;, label=f&#39;$\mu \pm 2\sigma$&#39;)
ax[1].axvline(x=errors_mean - 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;)
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;)
ax[1].legend()
ax[0].set(title=&#39;Model 3 - Test vs Predictions (Test Set)&#39;, xlabel=&#39;y_test&#39;, ylabel=&#39;y_pred&#39;);
ax[1].set(title=&#39;Model 3  - Errors&#39;, xlabel=&#39;error&#39;, ylabel=None);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_71_0.svg" title="fig:" alt="svg" />
</center>
</div>
<div id="example-4" class="section level3">
<h3>Example 4</h3>
<p>In this last example we consider a non-linear trend component.</p>
<ul>
<li>Non-Linear Trend Component</li>
</ul>
<pre class="python"><code># Generate trend component. 
def non_linear_trend(x):
    &quot;&quot;&quot;Scale and take square root.&quot;&quot;&quot;
    trend_comp = 0.2 * np.power(x, 1/2)
    return trend_comp

# Compute non-linear trend. 
data_df [&#39;tr2&#39;] = data_df[&#39;t&#39;].apply(non_linear_trend)

# Add trend to target variable. 
data_df [&#39;y4&#39;] = data_df [&#39;y3&#39;] + data_df [&#39;tr2&#39;]</code></pre>
<p>Let us see the trend plot:</p>
<pre class="python"><code>fig, ax = plt.subplots()
sns.lineplot(x=&#39;t&#39;, y=&#39;y4&#39;, data=data_df, color=sns_c[0], label=&#39;y4&#39;, ax=ax)
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Sample Data 4&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_76_0.svg" title="fig:" alt="svg" />
</center>
</div>
<div id="define-model-3" class="section level3">
<h3>Define Model</h3>
<p>Instead of an <code>RBF</code> kernel to model the trendd, we use a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RationalQuadratic.html"><code>RationalQuadratic</code></a> which <em>can seen as a scale mixture (an infinite sum) of RBF kernels with different characteristic length-scales</em>.</p>
<pre class="python"><code>from sklearn.gaussian_process.kernels import RationalQuadratic

k0 = WhiteKernel(noise_level=0.3**2, noise_level_bounds=(0.1**2, 0.5**2))

k1 = ConstantKernel(constant_value=2) * \
  ExpSineSquared(length_scale=1.0, periodicity=40, periodicity_bounds=(35, 45))

k2 = ConstantKernel(constant_value=100, constant_value_bounds=(1, 500)) * \
  RationalQuadratic(length_scale=500, length_scale_bounds=(1, 1e4), alpha= 50.0, alpha_bounds=(1, 1e3))

k3 = ConstantKernel(constant_value=1) * \
  ExpSineSquared(length_scale=1.0, periodicity=12, periodicity_bounds=(10, 15))

kernel_4  = k0 + k1 + k2 + k3</code></pre>
<pre class="python"><code># Define GaussianProcessRegressor object. 
gp4 = GaussianProcessRegressor(
    kernel=kernel_4, 
    n_restarts_optimizer=10, 
    normalize_y=True,
    alpha=0.0
)</code></pre>
</div>
<div id="split-data-3" class="section level3">
<h3>Split Data</h3>
<pre class="python"><code>y = data_df[&#39;y4&#39;].values.reshape(n ,1)
y_train = y[:n_train]
y_test = y[n_train:]</code></pre>
</div>
<div id="prior-sampling-3" class="section level3">
<h3>Prior Sampling</h3>
<pre class="python"><code>gp4_prior_samples = gp4.sample_y(X=X_train, n_samples=100)

fig, ax = plt.subplots()
for i in range(100):
    sns.lineplot(x=X_train[...,0], y = gp4_prior_samples[:, i], color=sns_c[1], alpha=0.2, ax=ax)
sns.lineplot(x=X_train[...,0], y=y_train[..., 0], color=sns_c[0], label=&#39;y3&#39;, ax=ax) 
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;GP4 Prior Samples&#39;, xlabel=&#39;t&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_83_0.svg" title="fig:" alt="svg" />
</center>
</div>
<div id="model-fit-predictions-3" class="section level3">
<h3>Model Fit + Predictions</h3>
<pre class="python"><code>gp4.fit(X_train, y_train)</code></pre>
<pre><code>GaussianProcessRegressor(alpha=0.0,
                         kernel=WhiteKernel(noise_level=0.09) + 1.41**2 * ExpSineSquared(length_scale=1, periodicity=40) + 10**2 * RationalQuadratic(alpha=50, length_scale=500) + 1**2 * ExpSineSquared(length_scale=1, periodicity=12),
                         n_restarts_optimizer=10, normalize_y=True)</code></pre>
<pre class="python"><code>y_pred, y_std = gp4.predict(X, return_std=True)

data_df[&#39;y_pred&#39;] = y_pred
data_df[&#39;y_std&#39;] = y_std
data_df[&#39;y_pred_lwr&#39;] = data_df[&#39;y_pred&#39;] - 2*data_df[&#39;y_std&#39;]
data_df[&#39;y_pred_upr&#39;] = data_df[&#39;y_pred&#39;] + 2*data_df[&#39;y_std&#39;]</code></pre>
<p>Finally, let us plot the prediction:</p>
<pre class="python"><code>fig, ax = plt.subplots()

ax.fill_between(
    x=data_df[&#39;t&#39;], 
    y1=data_df[&#39;y_pred_lwr&#39;], 
    y2=data_df[&#39;y_pred_upr&#39;], 
    color=sns_c[2], 
    alpha=0.15, 
    label=&#39;credible_interval&#39;
)

sns.lineplot(x=&#39;t&#39;, y=&#39;y4&#39;, data=data_df, color=sns_c[0], label = &#39;y4&#39;, ax=ax)
sns.lineplot(x=&#39;t&#39;, y=&#39;y_pred&#39;, data=data_df, color=sns_c[2], label=&#39;y_pred&#39;, ax=ax)

ax.axvline(n_train, color=sns_c[3], linestyle=&#39;--&#39;, label=&#39;train-test split&#39;)
ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
ax.set(title=&#39;Prediction Sample Data 4&#39;, xlabel=&#39;t&#39;, ylabel=&#39;&#39;);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_88_0.svg" title="fig:" alt="svg" />
</center>
<pre class="python"><code>print(f&#39;R2 Score Train = {gp4.score(X=X_train, y=y_train): 0.3f}&#39;)
print(f&#39;R2 Score Test = {gp4.score(X=X_test, y=y_test): 0.3f}&#39;)
print(f&#39;MAE Train = {mean_absolute_error(y_true=y_train, y_pred=gp4.predict(X_train)): 0.3f}&#39;)
print(f&#39;MAE Test = {mean_absolute_error(y_true=y_test, y_pred=gp4.predict(X_test)): 0.3f}&#39;)</code></pre>
<pre><code>R2 Score Train =  0.993
R2 Score Test =  0.957
MAE Train =  0.238
MAE Test =  0.320</code></pre>
</div>
<div id="errors-2" class="section level3">
<h3>Errors</h3>
<pre class="python"><code>errors = gp4.predict(X_test) - y_test
errors = errors.flatten()
errors_mean = errors.mean()
errors_std = errors.std()

fig, ax = plt.subplots(1, 2, figsize=(12, 6)) 
sns.regplot(x=y_test.flatten(), y=gp4.predict(X_test).flatten(), ax=ax[0])
sns.distplot(a=errors, ax=ax[1])
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;, label=f&#39;$\mu$&#39;)
ax[1].axvline(x=errors_mean + 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;, label=f&#39;$\mu \pm 2\sigma$&#39;)
ax[1].axvline(x=errors_mean - 2*errors_std, color=sns_c[4], linestyle=&#39;--&#39;)
ax[1].axvline(x=errors_mean, color=sns_c[3], linestyle=&#39;--&#39;)
ax[1].legend()
ax[0].set(title=&#39;Model 4 - Test vs Predictions (Test Set)&#39;, xlabel=&#39;y_test&#39;, ylabel=&#39;y_pred&#39;);
ax[1].set(title=&#39;Model 4  - Errors&#39;, xlabel=&#39;error&#39;, ylabel=None);</code></pre>
<center>
<img src="../images/gaussian_process_time_series_files/gaussian_process_time_series_91_0.svg" title="fig:" alt="svg" />
</center>
<p>Again, the aim of this notebook was to give a flavor on how to use Gaussian processes for time series forecasting. I <strong>strongly encourage</strong> you to go to the references presented above to get a deeper and much more complete exposition of this subject.</p>
</div>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/dockerfile.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'G-5NM5EDH834', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

